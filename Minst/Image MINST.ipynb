{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cProfile\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import cv2 as cv2\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog, graycomatrix, graycoprops\n",
    "from skimage.filters import gabor_kernel, gabor\n",
    "from skimage import img_as_float32\n",
    "from skimage.transform import resize\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 785 entries, label to 28x28\n",
      "dtypes: int64(785)\n",
      "memory usage: 359.3 MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('mnist_train.csv')\n",
    "test  = pd.read_csv('mnist_test.csv')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_values: (60000, 28, 28)\n",
      "Shape of train_target_encoded: (60000, 10)\n",
      "Shape of test_values: (10000, 28, 28)\n",
      "Shape of test_target_encoded: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "\n",
    "train_target = train['label']\n",
    "test_target = test['label']\n",
    "\n",
    "train_values = train.drop('label', axis=1)\n",
    "test_values = test.drop('label', axis=1)\n",
    "\n",
    "train_values = train_values.values.reshape(-1, 28, 28) \n",
    "test_values = test_values.values.reshape(-1, 28, 28)\n",
    "\n",
    "train_target_encoded = encoder.fit_transform(train_target.values.reshape(-1, 1)).toarray()\n",
    "test_target_encoded = encoder.transform(test_target.values.reshape(-1, 1)).toarray()\n",
    "\n",
    "print(\"Shape of train_values:\", train_values.shape)\n",
    "print(\"Shape of train_target_encoded:\", train_target_encoded.shape)\n",
    "\n",
    "print(\"Shape of test_values:\", test_values.shape)\n",
    "print(\"Shape of test_target_encoded:\", test_target_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_values\n",
    "X_train = train_values.astype(np.uint8)\n",
    "\n",
    "y_train_ENC = train_target_encoded\n",
    "y_train = np.argmax(y_train_ENC, axis=1)\n",
    "\n",
    "X_test = test_values\n",
    "X_test = test_values.astype(np.uint8)\n",
    "\n",
    "y_test_ENC = test_target_encoded\n",
    "y_test = np.argmax(y_test_ENC, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizacja histogramem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sprawdzenie i konwersja typu danych\n",
    "# if X_train.dtype != np.uint8:\n",
    "#     X_train = X_train.astype(np.float32)\n",
    "# if X_test.dtype != np.uint8:\n",
    "#     X_test = X_test.astype(np.float32)\n",
    "\n",
    "# Sprawdzenie i ewentualna korekta kształtu danych\n",
    "if X_train.shape[1:] != (28, 28):\n",
    "    X_train = X_train.reshape(-1, 28, 28)\n",
    "if X_test.shape[1:] != (28, 28):\n",
    "    X_test = X_test.reshape(-1, 28, 28)\n",
    "\n",
    "# Wyrównywanie histogramu\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train[i] = cv2.equalizeHist(X_train[i])\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test[i] = cv2.equalizeHist(X_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Powiększanie i wygładzenie obrazu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enlarge_and_smooth(image, new_size):\n",
    "    \"\"\"Powiększa obraz za pomocą interpolacji bicubic.\"\"\"\n",
    "    enlarged_image = cv2.resize(image, new_size, interpolation=cv2.INTER_CUBIC)\n",
    "    return enlarged_image\n",
    "\n",
    "# # Sztuczne zwiększenie rozmiaru obrazu \n",
    "# sample_indices = np.random.choice(X_train.shape[0], 5, replace=False)\n",
    "\n",
    "# # Dla każdego wybranego obrazu\n",
    "# for idx in sample_indices:\n",
    "#     # Oryginalny obraz\n",
    "#     original_image = X_train[idx]\n",
    "\n",
    "#     # Powiększony i wygładzony obraz\n",
    "#     enlarged_smoothed_image = enlarge_and_smooth(original_image, new_size=(42, 42))  # Przykładowy nowy rozmiar\n",
    "\n",
    "#     # Wyświetl oryginalny i przekształcony obraz obok siebie\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "#     sns.heatmap(original_image, cmap=\"viridis\", ax=axes[0])\n",
    "#     axes[0].set_title(f'Oryginalny obraz ({idx})')\n",
    "\n",
    "#     sns.heatmap(enlarged_smoothed_image, cmap=\"viridis\", ax=axes[1])\n",
    "#     axes[1].set_title(f'Powiększony i wygładzony obraz (Lanczos4) ({idx})')\n",
    "\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdzenie modelu wykorzystując SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Baseline accuracy without transformations\n",
    "# X_train_base, X_val_base, y_train_base, y_val_base = train_test_split(X_train, y_train, test_size=0.2, random_state=69)\n",
    "\n",
    "# qda_base = QDA()\n",
    "# qda_base.fit(X_train_base.reshape(X_train_base.shape[0], -1), y_train_base)  # Flatten images for QDA\n",
    "# y_pred_qda_base = qda_base.predict(X_val_base.reshape(X_val_base.shape[0], -1))\n",
    "# accuracy_qda_base = accuracy_score(y_val_base, y_pred_qda_base)\n",
    "\n",
    "# svm_base = SVC()\n",
    "# svm_base.fit(X_train_base.reshape(X_train_base.shape[0], -1), y_train_base)  # Flatten images for SVM\n",
    "# y_pred_svm_base = svm_base.predict(X_val_base.reshape(X_val_base.shape[0], -1))\n",
    "# accuracy_svm_base = accuracy_score(y_val_base, y_pred_svm_base)\n",
    "\n",
    "# print(\"Baseline QDA accuracy:\", accuracy_qda_base)\n",
    "# print(\"Baseline SVM accuracy:\", accuracy_svm_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline QDA accuracy: 0.5525\n",
    "\n",
    "\n",
    "Baseline SVM accuracy: 0.9793"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deklaracja funkcji dla ekstrakcji cech z obrazu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_hog_parallel(images, orientations=None, pixels_per_cell=None, cells_per_block=None, n_jobs=-1):\n",
    "    \"\"\"Oblicza deskryptory HOG dla obrazu.\"\"\"\n",
    "    \n",
    "     # Ustawienie wartości domyślnych, jeśli parametry nie są podane\n",
    "    if orientations is None:\n",
    "        orientations = 9\n",
    "    if pixels_per_cell is None:\n",
    "        pixels_per_cell = (8, 8)\n",
    "    if cells_per_block is None:\n",
    "        cells_per_block = (2, 2)\n",
    "    \n",
    "    def calculate_hog(image, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block):\n",
    "        \n",
    "        image = img_as_float32(image)\n",
    "\n",
    "        fd = hog(image, orientations=orientations, pixels_per_cell=pixels_per_cell,\n",
    "                cells_per_block=cells_per_block, visualize=False, channel_axis=None)\n",
    "\n",
    "        return fd\n",
    "    \n",
    "    return Parallel(n_jobs=n_jobs)(delayed(calculate_hog)(image, orientations, pixels_per_cell, cells_per_block) for image in images)\n",
    "\n",
    "\n",
    "def apply_gabor_filters_parallel(images, thetas=None, sigmas=None, frequencies=None, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Stosuje filtry Gabora do wielu obrazów równolegle.\n",
    "\n",
    "    Argumenty:\n",
    "        images: Lista obrazów wejściowych.\n",
    "        thetas: (Opcjonalnie) Lista kątów orientacji filtrów Gabora (w radianach). Jeśli None, używane są wartości domyślne.\n",
    "        sigmas: (Opcjonalnie) Lista odchyleń standardowych filtrów Gabora. Jeśli None, używane są wartości domyślne.\n",
    "        frequencies: (Opcjonalnie) Lista częstotliwości przestrzennych filtrów Gabora. Jeśli None, używane są wartości domyślne.\n",
    "        n_jobs: Liczba rdzeni procesora do wykorzystania podczas zrównoleglania. -1 oznacza użycie wszystkich dostępnych rdzeni.\n",
    "\n",
    "    Zwraca:\n",
    "        Listę tablic NumPy zawierających obrazy przefiltrowane filtrami Gabora, o typie danych float32.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ustawienie wartości domyślnych, jeśli parametry nie są podane\n",
    "    if thetas is None:\n",
    "        thetas = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    if sigmas is None:\n",
    "        sigmas = [1, 3]\n",
    "    if frequencies is None:\n",
    "        frequencies = [0.05, 0.25]\n",
    "\n",
    "    def apply_gabor_filters_single(image):\n",
    "        image = img_as_float32(image)\n",
    "        filtered_images = [gabor(image, frequency, theta=theta, sigma_x=sigma, sigma_y=sigma)[0]\n",
    "                           for theta in thetas for sigma in sigmas for frequency in frequencies]\n",
    "        return np.array(filtered_images, dtype=np.float32)\n",
    "\n",
    "    return Parallel(n_jobs=n_jobs)(delayed(apply_gabor_filters_single)(image) for image in images)\n",
    "\n",
    "\n",
    "def extract_features_HOG_Gabor(X, hog_orientations=None, hog_pixels_per_cell=None, hog_cells_per_block=None, \n",
    "                              gabor_thetas=None, gabor_sigmas=None, gabor_frequencies=None):\n",
    "    \"\"\"Generator zwracający cechy HOG i Gabora dla obrazów.\"\"\"\n",
    "\n",
    "    hog_features_list = calculate_hog_parallel(X, orientations=hog_orientations, pixels_per_cell=hog_pixels_per_cell, cells_per_block=hog_cells_per_block)\n",
    "    gabor_features_list = apply_gabor_filters_parallel(X, thetas=gabor_thetas, sigmas=gabor_sigmas, frequencies=gabor_frequencies)\n",
    "\n",
    "    for hog_features, gabor_features in zip(hog_features_list, gabor_features_list):\n",
    "        \n",
    "        gabor_features_flattened = np.array([img.flatten() for img in gabor_features])\n",
    "\n",
    "        # Dopasowujemy kształt hog_features do gabor_features_flattened\n",
    "        hog_features_reshaped = np.repeat(hog_features.reshape(1, -1), gabor_features_flattened.shape[0], axis=0)\n",
    "\n",
    "        # Łączymy cechy HOG i Gabora w poziomie\n",
    "        concatenated_features = np.hstack((hog_features_reshaped, gabor_features_flattened))\n",
    "\n",
    "        concatenated_features = concatenated_features.flatten()\n",
    "\n",
    "        yield concatenated_features\n",
    "\n",
    "#################################################################################################################################################\n",
    "################################################  Directional filters, ORB    ###################################################################\n",
    "\n",
    "def apply_directional_filters(image, kernel_sizes=[3, 5, 7]):\n",
    "    \"\"\"Stosuje filtry kierunkowe do obrazu.\"\"\"\n",
    "    filtered_images = []\n",
    "    for kernel_size in kernel_sizes:\n",
    "        kernel_horizontal = cv2.getDerivKernels(1, 0, kernel_size, normalize=True)\n",
    "        kernel_vertical = cv2.getDerivKernels(0, 1, kernel_size, normalize=True)\n",
    "        filtered_horizontal = cv2.filter2D(image, cv2.CV_32F, kernel_horizontal[0])\n",
    "        filtered_vertical = cv2.filter2D(image, cv2.CV_32F, kernel_vertical[0])\n",
    "        filtered_images.append(filtered_horizontal.flatten())\n",
    "        filtered_images.append(filtered_vertical.flatten())\n",
    "        if kernel_size % 2 == 0 or kernel_size > 31:\n",
    "            raise ValueError(f\"Nieprawidłowy rozmiar jądra: {kernel_size}. Rozmiar jądra musi być nieparzysty i nie większy niż 31.\")\n",
    "    return np.array(filtered_images).squeeze()\n",
    "\n",
    "def extract_orb_features(image, nfeatures=500):\n",
    "    \"\"\"Wyodrębnia cechy ORB z obrazu.\"\"\"\n",
    "    orb = cv2.ORB_create(nfeatures=nfeatures)  \n",
    "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
    "    if descriptors is None:\n",
    "        return np.zeros(nfeatures * 32)  \n",
    "    return descriptors.flatten()\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################################################################\n",
    "################################################  GLCM, Zernike    ##############################################################################\n",
    "def extract_glcm_features(image, distances=[1], angles=[0], properties=['contrast', 'energy', 'homogeneity', 'correlation']):\n",
    "    \"\"\"Wyodrębnia cechy GLCM z obrazu.\"\"\"\n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    glcm = graycomatrix(image, distances=distances, angles=angles, levels=256, symmetric=True, normed=True)\n",
    "\n",
    "    features = []\n",
    "    for prop in properties:\n",
    "        features.extend(graycoprops(glcm, prop).flatten())\n",
    "\n",
    "    return np.array(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testowanie modelu dla HOG i filtrów Gabora i porównanie wydajności przy zastosowaniu redukcji wymiarów. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_and_evaluate_models(X_train, y_train, use_pca=True):\n",
    "#     \"\"\"\n",
    "#     Trenuje i ocenia modele QDA i SVC, opcjonalnie z redukcją wymiarów PCA.\n",
    "\n",
    "#     Argumenty:\n",
    "#         X_train: Dane treningowe.\n",
    "#         y_train: Etykiety treningowe.\n",
    "#         use_pca: Flaga wskazująca, czy używać PCA (domyślnie True).\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Ekstrakcja cech HOG i Gabor za pomocą generatora\n",
    "#     X_train_features = np.array(list(extract_features_HOG_Gabor(X_train)))\n",
    "\n",
    "#     # Podział na zbiór treningowy i walidacyjny\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X_train_features, y_train, test_size=0.2, random_state=69)\n",
    "\n",
    "#     # Redukcja wymiarów (opcjonalnie)\n",
    "#     if use_pca:\n",
    "#         pca_dim = PCA(n_components=50)\n",
    "#         X_train = pca_dim.fit_transform(X_train)\n",
    "#         X_val = pca_dim.transform(X_val)\n",
    "\n",
    "#     # Tworzenie i trenowanie modelu QDA\n",
    "#     qda = QDA()\n",
    "#     qda.fit(X_train, y_train)\n",
    "\n",
    "#     # Tworzenie i trenowanie modelu SVC\n",
    "#     svc = SVC(kernel='rbf')\n",
    "#     svc.fit(X_train, y_train)\n",
    "\n",
    "#     # Ocena modelu\n",
    "#     y_pred_qda = qda.predict(X_val)\n",
    "#     accuracy_qda = accuracy_score(y_val, y_pred_qda)\n",
    "\n",
    "#     y_pred_svc = svc.predict(X_val)\n",
    "#     accuracy_svc = accuracy_score(y_val, y_pred_svc)\n",
    "\n",
    "#     print(\"Dokładność QDA HOG i Gabor\", \"po PCA:\" if use_pca else \":\", accuracy_qda)\n",
    "#     print(\"Dokładność SVC HOG i Gabor\", \"po PCA:\" if use_pca else \":\", accuracy_svc)\n",
    "\n",
    "# # Test z PCA\n",
    "# train_and_evaluate_models(X_train, y_train, use_pca=True)\n",
    "#train_and_evaluate_models(X_train, y_train, use_pca=False)\n",
    "#cProfile.run('train_and_evaluate_models(X_train, y_train, use_pca=True)') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokładność QDA HOG i Gabor       : 0.5734\n",
    "\n",
    "\n",
    "Dokładność SVC HOG i Gabor       : 0.987\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dokładność QDA HOG i Gabor po PCA: 0.9701\n",
    "\n",
    "\n",
    "Dokładność SVC HOG i Gabor po PCA: 0.9869\n",
    "\n",
    "Czas obliczeń dla PCA 3min vs 30min bez PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTUNA dla HOG, Gabor, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", module=\"optuna\")\n",
    "\n",
    "\n",
    "# def objective(trial, X_train, y_train):\n",
    "#     \"\"\"\n",
    "#     Funkcja celu dla optymalizacji Optuna. \n",
    "#     Przyjmuje próbę (trial), dane treningowe (X_train) i etykiety (y_train).\n",
    "#     Zwraca dokładność QDA i SVM na danych walidacyjnych po zastosowaniu sekwencji transformacji.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Parametry HOG\n",
    "#     orientations      = trial.suggest_int(\"hog_orientations\", 2, 16)\n",
    "#     pixels_per_cell   = trial.suggest_categorical(\"hog_pixels_per_cell\", [str((2, 2)), str((2, 3)), str((3, 2)), str((3, 3)), str((4, 4)), str((5, 5)),str((6, 6)), str((7, 7))])\n",
    "#     cells_per_block   = trial.suggest_categorical(\"hog_cells_per_block\", [str((1, 1)), str((2, 2)), str((3, 3)), str((4, 4))])\n",
    "\n",
    "#     # Parametry filtrów Gabora\n",
    "#     gabor_thetas      = trial.suggest_categorical(\"gabor_thetas\", ([0],  [np.pi / 14],  [np.pi / 12], [0, np.pi / 14 ], [0, np.pi / 12 ] ))\n",
    "#     gabor_sigmas      = trial.suggest_categorical(\"gabor_sigmas\", ([0.33], [0.66], [1], [0.33 , 1.25], [0.66, 2.35], [1, 3]))\n",
    "#     gabor_frequencies = trial.suggest_categorical(\"gabor_frequencies\", ([0.025], [0.05], [0.125], [0.025, 0.125], [0.05, 0.175], [0.05, 0.25]))\n",
    "        \n",
    "#     #PCA\n",
    "#     PCA_n_components  =  trial.suggest_int(\"PCA_Components\", 4, 228)\n",
    "#     kernel = trial.suggest_categorical(\"kernel_pca_kernel\", ['linear', 'poly', 'rbf', 'sigmoid', 'cosine'])\n",
    "#     gamma = None\n",
    "#     if kernel in ['poly', 'rbf']:\n",
    "#         gamma = trial.suggest_loguniform(\"kernel_pca_gamma\", 0.001, 1)\n",
    "        \n",
    "#     # Powiększanie i wygładzanie\n",
    "#     # X_train_split = np.array([enlarge_and_smooth(img, new_size) for img in X_train])\n",
    "#     # X_val = np.array([enlarge_and_smooth(img, new_size) for img in X_val])\n",
    "    \n",
    "#     # Ekstrakcja cech HOG i Gabor\n",
    "#     X_train_features = np.array(list(extract_features_HOG_Gabor(\n",
    "#         X_train, \n",
    "#         hog_orientations=orientations, \n",
    "#         hog_pixels_per_cell=eval(pixels_per_cell), # Konwersja stringa na krotkę\n",
    "#         hog_cells_per_block=eval(cells_per_block),  # Konwersja stringa na krotkę\n",
    "#         gabor_thetas=gabor_thetas, \n",
    "#         gabor_sigmas=gabor_sigmas, \n",
    "#         gabor_frequencies=gabor_frequencies\n",
    "#     )))\n",
    "\n",
    "#     # Podział na zbiór treningowy i walidacyjny\n",
    "#     X_train_filters, X_val_filters, y_train_filters, y_val_filters = train_test_split(X_train_features, y_train, test_size=0.2, random_state=69)\n",
    "    \n",
    "    \n",
    "#     # Kernel PCA\n",
    "#     kpca = KernelPCA(n_components=PCA_n_components, kernel=kernel, gamma=gamma)\n",
    "#     X_train_reduced = kpca.fit_transform(X_train_filters)\n",
    "#     X_val_reduced = kpca.transform(X_val_filters)\n",
    "                \n",
    "#     # SVC\n",
    "#     svc = SVC(kernel='rbf')\n",
    "#     svc.fit(X_train_reduced, y_train_filters)\n",
    "#     y_pred_svm = svc.predict(X_val_reduced)\n",
    "#     accuracy_svm = accuracy_score(y_val_filters, y_pred_svm)\n",
    "\n",
    "#     return accuracy_svm\n",
    "\n",
    "# # Optymalizacji\n",
    "                            \n",
    "# study = optuna.create_study(directions=[\"maximize\"], sampler=optuna.samplers.CmaEsSampler() ) \n",
    "# study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=100, n_jobs=1)\n",
    "\n",
    "\n",
    "# print(\"Best parameters:\", study.best_params)\n",
    "# print(\"Best QDA accuracy:\", study.best_trial.values[0]) \n",
    "# print(\"Best SVM accuracy:\", study.best_trial.values[1]) \n",
    "\n",
    "# # [I 2024-09-17 05:43:37,964] Trial 13 finished with value: 0.99133 and parameters: {'hog_orientations': 16, 'hog_pixels_per_cell': '(4, 4)', 'hog_cells_per_block': '(3, 3)', 'gabor_thetas': [0.2243994752564138], 'gabor_sigmas': [0.66, 2.35], 'gabor_frequencies': [0.025], 'PCA_Components': 209, 'kernel_pca_kernel': 'cosine'}. Best is trial 13 with value: 0.9913333333333333.\n",
    "# # [I 2024-09-17 08:45:58,345] Trial 19 finished with value: 0.99175 and parameters: {'hog_orientations': 6, 'hog_pixels_per_cell': '(2, 3)', 'hog_cells_per_block': '(2, 2)', 'gabor_thetas': [0.2617993877991494], 'gabor_sigmas': [1], 'gabor_frequencies': [0.025], 'PCA_Components': 132, 'kernel_pca_kernel': 'sigmoid'}. Best is trial 19 with value: 0.99175.\n",
    "# # [I 2024-09-17 10:45:29,605] Trial 23 finished with value: 0.99225 and parameters: {'hog_orientations': 6, 'hog_pixels_per_cell': '(3, 3)', 'hog_cells_per_block': '(2, 2)', 'gabor_thetas': [0], 'gabor_sigmas': [1], 'gabor_frequencies': [0.05, 0.25], 'PCA_Components': 150, 'kernel_pca_kernel': 'cosine'}. Best is trial 23 with value: 0.99225.\n",
    "# # [I 2024-09-17 13:24:59,082] Trial 28 finished with value: 0.99108 and parameters: {'hog_orientations': 9, 'hog_pixels_per_cell': '(3, 2)', 'hog_cells_per_block': '(1, 1)', 'gabor_thetas': [0, 0.2617993877991494], 'gabor_sigmas': [1], 'gabor_frequencies': [0.05, 0.25], 'PCA_Components': 190, 'kernel_pca_kernel': 'sigmoid'}. Best is trial 23 with value: 0.99225.\n",
    "# # [I 2024-09-17 13:54:44,248] Trial 29 finished with value: 0.9915 and parameters: {'hog_orientations': 7, 'hog_pixels_per_cell': '(4, 4)', 'hog_cells_per_block': '(4, 4)', 'gabor_thetas': [0.2617993877991494], 'gabor_sigmas': [0.66, 2.35], 'gabor_frequencies': [0.05], 'PCA_Components': 164, 'kernel_pca_kernel': 'cosine'}. Best is trial 23 with value: 0.99225.\n",
    "# # [I 2024-09-17 18:02:03,444] Trial 37 finished with value: 0.99066 and parameters: {'hog_orientations': 9, 'hog_pixels_per_cell': '(3, 2)', 'hog_cells_per_block': '(4, 4)', 'gabor_thetas': [0], 'gabor_sigmas': [0.66, 2.35], 'gabor_frequencies': [0.05, 0.175], 'PCA_Components': 169, 'kernel_pca_kernel': 'rbf', 'kernel_pca_gamma': 0.0032186977490984547}. Best is trial 23 with value: 0.99225.\n",
    "# # [I 2024-09-17 19:02:58,946] Trial 39 finished with value: 0.9915 and parameters: {'hog_orientations': 6, 'hog_pixels_per_cell': '(4, 4)', 'hog_cells_per_block': '(4, 4)', 'gabor_thetas': [0, 0.2243994752564138], 'gabor_sigmas': [1, 3], 'gabor_frequencies': [0.125], 'PCA_Components': 148, 'kernel_pca_kernel': 'linear'}. Best is trial 23 with value: 0.99225.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wykorzystanie wcześniej otrzymanch hiperparamatrów dla HOG i filtrów Gabora po KPCA w celu stworzenia wektora cech z obrazów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_features = np.array(list(extract_features_HOG_Gabor(\n",
    "#         X_train, \n",
    "#         hog_orientations=6, \n",
    "#         hog_pixels_per_cell=eval('(3, 3)'), \n",
    "#         hog_cells_per_block=eval('(2, 2)'),  \n",
    "#         gabor_thetas=[0], \n",
    "#         gabor_sigmas=[1], \n",
    "#         gabor_frequencies=[0.05, 0.25]\n",
    "#     )))\n",
    "\n",
    "\n",
    "# kpca = KernelPCA(n_components=150, kernel='cosine')\n",
    "\n",
    "# X_train_filters, X_val_filters, y_train_filters, y_val_filters = train_test_split(X_train_features, y_train_ENC, test_size=0.2, random_state=69)\n",
    "\n",
    "# X_train_reduced = kpca.fit_transform(X_train_filters)\n",
    "# X_val_reduced = kpca.transform(X_val_filters)\n",
    "\n",
    "\n",
    "# np.save('X_train_reduced.npy', X_train_reduced)\n",
    "# np.save('X_val_reduced.npy', X_val_reduced)\n",
    "# np.save('y_train_filters.npy', y_train_filters)\n",
    "# np.save('y_val_filters.npy', y_val_filters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pierwszy model na sieci konwolucyjnej dla bazy z HOG i Gabora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, LayerNormalization , BatchNormalization, PReLU , Input, ActivityRegularization, GlobalAveragePooling1D, SeparableConv1D \n",
    "# from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "# from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Lion\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# import gc\n",
    "\n",
    "\n",
    "\n",
    "# X_train_reduced = np.load('X_train_reduced.npy')\n",
    "# X_val_reduced = np.load('X_val_reduced.npy')\n",
    "# y_train_filters = np.load('y_train_filters.npy')\n",
    "# y_val_filters = np.load('y_val_filters.npy')\n",
    "\n",
    "# X_train_reduced = X_train_reduced.reshape(X_train_reduced.shape[0], X_train_reduced.shape[1], 1)\n",
    "# X_val_reduced = X_val_reduced.reshape(X_val_reduced.shape[0], X_val_reduced.shape[1], 1)\n",
    "\n",
    "# def calculate_max_pool_size(input_length, prev_pool_size, min_output_size=2):\n",
    "#     calculated_pool_size = input_length // prev_pool_size\n",
    "#     return max(min_output_size, calculated_pool_size)\n",
    "\n",
    "\n",
    "# def objective(trial):\n",
    "#     \"\"\"Funkcja celu dla Optuny.\"\"\"\n",
    "#     #os.environ['TF_NUM_INTRAOP_THREADS'] = '1' ## Czy Kers działa na pojedycznym wątku ????\n",
    "#     gc.collect()\n",
    "#     tf.keras.backend.clear_session()\n",
    "#     gc.collect()\n",
    "\n",
    "#     activation_functions = ['relu', 'elu', 'leaky_relu', 'tanh']\n",
    "#     activation = trial.suggest_categorical('activation', activation_functions)\n",
    "\n",
    "#     # Definiowanie modelu\n",
    "#     model = Sequential()\n",
    "#     model.add(Input(shape=(X_train_reduced.shape[1], 1)))\n",
    "\n",
    "#     # Pierwsza warstwa konwolucyjna\n",
    "#     model.add(Conv1D(filters=trial.suggest_int('conv1d_filters_1', 48, 450),\n",
    "#                      kernel_size=trial.suggest_int('kernel_size_1', 2, 16),\n",
    "#                      #activation=activation,\n",
    "#                      padding='same', \n",
    "#                      #dilation_rate=trial.suggest_int('dilation_rate_1', 1, 4)\n",
    "#                      )\n",
    "#               )\n",
    "#     model.add(PReLU())                #$$$$$$$ LAYER przed PRelu\n",
    "#     model.add(LayerNormalization())   ######\n",
    "#     model.add(ActivityRegularization(l1=trial.suggest_float('l1_1', 1e-6, 1e-1, log=True), \n",
    "#                                      l2=trial.suggest_float('l2_1', 1e-6, 1e-1, log=True)\n",
    "#                                      )\n",
    "#               )\n",
    "#     pool_size_1 = trial.suggest_int('pool_size_1', 2, 10)\n",
    "#     model.add(MaxPooling1D(pool_size=pool_size_1))\n",
    "\n",
    "\n",
    "\n",
    "#     # Druga warstwa konwolucyjna\n",
    "#     input_length_2 = X_train_reduced.shape[1] // pool_size_1\n",
    "#     model.add(Conv1D(filters=trial.suggest_int('conv1d_filters_2', 24, 400),\n",
    "#                      kernel_size=trial.suggest_int('kernel_size_2', 2, 14),\n",
    "#                      padding='same',\n",
    "#                      #activation=activation,\n",
    "#                      #dilation_rate=trial.suggest_int('dilation_rate_2', 1, 4)\n",
    "#                      )\n",
    "#               )\n",
    "#     model.add(PReLU())\n",
    "#     model.add(LayerNormalization())\n",
    "#     model.add(ActivityRegularization(l1=trial.suggest_float('l1_2', 1e-6, 1e-1, log=True), \n",
    "#                                      l2=trial.suggest_float('l2_2', 1e-6, 1e-1, log=True)\n",
    "#                                      )\n",
    "#               )\n",
    "#     pool_size_2 = trial.suggest_int('pool_size_2', 2, input_length_2 // 2)\n",
    "#     #pool_size_2 = trial.suggest_int('pool_size_2', 2, 10)\n",
    "#     model.add(MaxPooling1D(pool_size=pool_size_2))\n",
    "\n",
    "\n",
    "\n",
    "#     # Trzecia warstwa konwolucyjna\n",
    "#     #input_length_3 = input_length_2 // pool_size_2\n",
    "#     model.add(Conv1D(filters=trial.suggest_int('conv1d_filters_3', 32, 300),\n",
    "#                      kernel_size=trial.suggest_int('kernel_size_3', 2, 12),\n",
    "#                      padding='same',\n",
    "#                      )\n",
    "#               )\n",
    "#     model.add(PReLU())\n",
    "#     model.add(LayerNormalization())\n",
    "#     model.add(Dropout(rate=trial.suggest_float('dropout_rate_3', 0.01, 0.5)\n",
    "#                       )\n",
    "#               )\n",
    "#     #pool_size_3 = trial.suggest_int('pool_size_3', 2, max(2, input_length_3 // 2))\n",
    "#     #pool_size_3 = trial.suggest_int('pool_size_3', 2, 8)\n",
    "#     #model.add(MaxPooling1D(pool_size=pool_size_3))\n",
    "\n",
    "#     # Warstwy Dense\n",
    "#     model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "#     model.add(Dense(units=trial.suggest_int('dense_units_1', 40, 300), activation=activation))\n",
    "#     model.add(Dropout(rate=trial.suggest_float('dropout_rate_4', 0.01, 0.75)))\n",
    "    \n",
    "#     model.add(Dense(units=trial.suggest_int('dense_units_2', 20, 200), activation=activation))\n",
    "#     model.add(Dropout(rate=trial.suggest_float('dropout_rate_5', 0.01, 0.65)))\n",
    "    \n",
    "#     model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#     # Optymalizator\n",
    "#     lr_initial = trial.suggest_float(\"lr_initial\", 1e-5, 1e-1, log=True)\n",
    "#     decay_steps = trial.suggest_int(\"decay_steps\", 10, 150)\n",
    "#     decay_rate = trial.suggest_float(\"decay_rate\", 0.01, 0.99)\n",
    "#     lr_schedule = ExponentialDecay(initial_learning_rate=lr_initial,\n",
    "#                                   decay_steps=decay_steps,\n",
    "#                                   decay_rate=decay_rate)\n",
    "\n",
    "#     optimizer_name = trial.suggest_categorical('optimizer', ['Lion'])\n",
    "#     optimizer_class = getattr(tf.keras.optimizers, optimizer_name)\n",
    "#     optimizer = optimizer_class(learning_rate=lr_schedule)\n",
    "\n",
    "    \n",
    "#     model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     # Early Stopping\n",
    "#     early_stopping = EarlyStopping(monitor='val_accuracy', patience=16, start_from_epoch=10, min_delta = 0.00005)\n",
    "\n",
    "#     # Trenowanie modelu\n",
    "#     model.fit(X_train_reduced, y_train_filters,\n",
    "#               epochs=trial.suggest_int('epochs', 40, 150),\n",
    "#               batch_size=trial.suggest_int('batch_size', 64, 1920),\n",
    "#               validation_data=(X_val_reduced, y_val_filters),\n",
    "#               verbose=1,\n",
    "#               callbacks=[early_stopping])\n",
    "\n",
    "#     # Ewaluacja modelu\n",
    "#     _, accuracy = model.evaluate(X_val_reduced, y_val_filters, verbose=0)\n",
    "\n",
    "#     del model\n",
    "#     return accuracy\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler())\n",
    "# study.optimize(objective, n_trials=600, n_jobs=1, gc_after_trial=True) ## Czy keras działa na wszystkich wątkach, ale optuna na pojedynczym. \n",
    "\n",
    "\n",
    "# # Najlepsze parametry i wynik\n",
    "# print(\"Najlepsze parametry:\", study.best_params)\n",
    "# print(\"Najlepsza dokładność:\", study.best_value)\n",
    "\n",
    "# #[I 2024-10-04 05:18:28,377] Trial 26 finished with value: 0.9810000061988831 and parameters: {'activation': 'elu', 'conv1d_filters_1': 347, 'kernel_size_1': 7,  'l1_1': 0.0002141584459916536, 'l2_1': 4.201061472934882e-06, 'pool_size_1': 6, 'conv1d_filters_2': 77, 'kernel_size_2': 14, 'l1_2': 3.203529032832527e-06, 'l2_2': 0.00015793896479891322, 'pool_size_2': 2, 'conv1d_filters_3': 258, 'kernel_size_3': 4, 'dropout_rate_3': 0.3297488074504043, 'dense_units_1': 271, 'dropout_rate_4': 0.5097723961373417, 'dense_units_2': 78, 'dropout_rate_5': 0.15473996425601394, 'lr_initial': 0.0004175922071628326, 'decay_steps': 33, 'decay_rate': 0.9780884395210858, 'optimizer': 'Lion', 'epochs': 123, 'batch_size': 264}. Best is trial 26 with value: 0.9810000061988831.\n",
    "# #[I 2024-10-04 14:58:14,236] Trial 61 finished with value: 0.9797499775886536 and parameters: {'activation': 'elu', 'conv1d_filters_1': 424, 'kernel_size_1': 13, 'l1_1': 0.0005501543495144062, 'l2_1': 0.02794377888054429,   'pool_size_1': 7, 'conv1d_filters_2': 79, 'kernel_size_2': 12, 'l1_2': 1.3699264627909325e-06, 'l2_2': 6.577814668979489e-06, 'pool_size_2': 3, 'conv1d_filters_3': 280, 'kernel_size_3': 3, 'dropout_rate_3': 0.21341586312675653, 'dense_units_1': 292, 'dropout_rate_4': 0.22415600475665626, 'dense_units_2': 106, 'dropout_rate_5': 0.09686035013603865, 'lr_initial': 0.0004430745906851504, 'decay_steps': 22, 'decay_rate': 0.9872365423551039, 'optimizer': 'Lion', 'epochs': 150, 'batch_size': 216}. Best is trial 26 with value: 0.9810000061988831.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sieć CONV2D z zamrożonym PCA dla danych pierwotnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import keras\n",
    "# from keras import layers\n",
    "# import tensorflow_probability as tfp\n",
    "# import optuna\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# X_train_image, X_val_image, y_train_image, y_val_image = train_test_split(X_train, y_train_ENC, test_size=0.2, random_state=69)\n",
    "# X_train_image = X_train_image.astype('float32')\n",
    "# X_val_image = X_val_image.astype('float32')\n",
    "# X_train_image = np.expand_dims(X_train_image, axis=-1)  \n",
    "# X_val_image = np.expand_dims(X_val_image, axis=-1) \n",
    " \n",
    "# def objective(trial):\n",
    "#     # Przestrzeń hiperparametrów\n",
    "#     num_filters1 = trial.suggest_int(\"num_filters1\", 32, 256)    # Pierwsza warstwa Conv2d\n",
    "#     num_filters2 = trial.suggest_int(\"num_filters2\", 64, 256)    # Druga warstwa Conv2d\n",
    "#     num_filters3 = trial.suggest_int(\"num_filters3\", 128, 256)   # Trzecia warstwa Conv2d\n",
    "#     n_components = trial.suggest_int(\"PCA_components\", 350, 500) # PCA\n",
    "\n",
    "#     l1_1=trial.suggest_float('l1_1', 1e-6, 1e-1, log=True)\n",
    "#     l2_1=trial.suggest_float('l2_1', 1e-6, 1e-1, log=True)\n",
    "    \n",
    "#     l1_2=trial.suggest_float('l1_2', 1e-6, 1e-1, log=True)\n",
    "#     l2_2=trial.suggest_float('l2_2', 1e-6, 1e-1, log=True)\n",
    "\n",
    "#     l1_3=trial.suggest_float('l1_3', 1e-6, 1e-1, log=True)\n",
    "#     l2_3=trial.suggest_float('l2_3', 1e-6, 1e-1, log=True)\n",
    "    \n",
    "#     activation_functions = ['relu', 'gelu', 'leaky_relu', 'silu', 'mish']\n",
    "#     activation = trial.suggest_categorical('activation', activation_functions)\n",
    "    \n",
    "    \n",
    "#     # Warstwy konwolucyjne 2D\n",
    "#     conv_layers = [\n",
    "#         # Pierwsza warstwa Conv2d\n",
    "#         tf.keras.layers.Conv2D(\n",
    "#                                 num_filters1,\n",
    "#                                 kernel_size=2,\n",
    "#                                 activation=activation,\n",
    "#                                 kernel_regularizer=tf.keras.regularizers.l2(l2_1),\n",
    "#                                 bias_regularizer=tf.keras.regularizers.l1(l1_1),\n",
    "#                                 padding='same',\n",
    "#                                 input_shape=(X_train_image.shape[1:])\n",
    "#                                 ),\n",
    "        \n",
    "#         tf.keras.layers.MaxPool2D(pool_size=2,strides=1,\n",
    "#                                  ),\n",
    "#         # Druga warstwa Conv2d\n",
    "#         tf.keras.layers.Conv2D(\n",
    "#                                 num_filters2,\n",
    "#                                 kernel_size=2,\n",
    "#                                 activation=activation,\n",
    "#                                 kernel_regularizer=tf.keras.regularizers.l2(l2_2),\n",
    "#                                 bias_regularizer=tf.keras.regularizers.l1(l1_2),                                \n",
    "#                                 padding='same',\n",
    "#                                 ),\n",
    "#         tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "#         # Trzecia warstwa Conv2d\n",
    "#         tf.keras.layers.Conv2D(\n",
    "#                                 num_filters3,\n",
    "#                                 kernel_size=2,\n",
    "#                                 activation=activation,\n",
    "#                                 kernel_regularizer=tf.keras.regularizers.l2(l2_3),\n",
    "#                                 bias_regularizer=tf.keras.regularizers.l1(l1_3),                                \n",
    "#                                 padding='same'\n",
    "#                                 ),\n",
    "#         tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "        \n",
    "#         tf.keras.layers.Flatten(),\n",
    "#                 ]\n",
    "\n",
    "#     ### Obliczenia dla zamrożonego PCA na podstawie pierwszej inicjalizacji modelu\n",
    "#     conv_model = keras.models.Sequential(conv_layers)  \n",
    "#     X_train_PCA = conv_model.predict(X_train_image)\n",
    "    \n",
    "#     X_train_PCA = tf.reshape(X_train_PCA, [X_train_PCA.shape[0], -1])\n",
    "\n",
    "#     # Macierz kowariancji\n",
    "#     covariance_matrix = tfp.stats.covariance(X_train_PCA, sample_axis=0, event_axis=-1)\n",
    "#     # Wektory i wartości własne\n",
    "#     eigenvalues, eigenvectors = tf.linalg.eigh(covariance_matrix)\n",
    "#     sorted_indices = tf.argsort(eigenvalues, direction='DESCENDING')\n",
    "#     eigenvalues = tf.gather(eigenvalues, sorted_indices)\n",
    "#     eigenvectors = tf.gather(eigenvectors, sorted_indices, axis=1)\n",
    "    \n",
    "#     #### Opcja druga na SVD, ale wymaga jeszcze zabawy\n",
    "#     # s, u, v = tf.linalg.svd(covariance_matrix)\n",
    "#     # eigenvectors = v\n",
    "#     # eigenvalues = tf.square(s) \n",
    "    \n",
    "#     # Warstwa PCA\n",
    "#     model = keras.models.Sequential(conv_layers + [\n",
    "#         tf.keras.layers.Lambda(lambda x, eigenvectors: tf.matmul(x, eigenvectors), arguments={'eigenvectors': eigenvectors[:, :n_components]})\n",
    "#     ])\n",
    "\n",
    "#     # Output (klasyfikacja)\n",
    "#     model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "#     #model.summary()\n",
    "#     tf.keras.utils.plot_model(model, show_shapes=True, to_file='model.png')\n",
    "    \n",
    "\n",
    "#     # Optymalizator\n",
    "#     optimizer_name = trial.suggest_categorical('optimizer', ['AdamW'])\n",
    "#     optimizer_class = getattr(tf.keras.optimizers, optimizer_name)\n",
    "    \n",
    "#     # Początkową wartość learning rate\n",
    "#     lr_initial = trial.suggest_float(\"lr_initial\", 5e-3, 1e-1, log=True)\n",
    "#     optimizer = optimizer_class(learning_rate=lr_initial)  \n",
    "\n",
    "#     ## Kompilacja modelu\n",
    "#     model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "#     # Early Stopping\n",
    "#     early_stopping = EarlyStopping(monitor='categorical_accuracy', patience=8, start_from_epoch=8, min_delta=0.0001)\n",
    "    \n",
    "#     # ReduceLROnPlateau\n",
    "#     reduce_lr = ReduceLROnPlateau(\n",
    "#         monitor='val_loss',\n",
    "#         factor=trial.suggest_float(\"reduce_lr_factor\", 0.1, 0.9, step=0.1),\n",
    "#         patience=trial.suggest_int(\"reduce_lr_patience\", 2, 12),\n",
    "#         min_lr=trial.suggest_float(\"reduce_lr_min_lr\", 1e-7, 1e-4, log=True)\n",
    "#     )\n",
    "    \n",
    "#     # Trenowanie i ocena modelu\n",
    "#     history = model.fit(X_train_image, y_train_image,\n",
    "#                         epochs=trial.suggest_int('epochs', 15, 80),\n",
    "#                         batch_size=trial.suggest_int('batch_size', 64, 1920),\n",
    "#                         validation_data=(X_val_image, y_val_image),\n",
    "#                         callbacks=[early_stopping, reduce_lr]\n",
    "#                         )\n",
    "    \n",
    "#     accuracy = history.history['val_categorical_accuracy'][-1]\n",
    "\n",
    "#     return accuracy\n",
    "\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler())\n",
    "# study.optimize(objective, n_trials=600, n_jobs=1, gc_after_trial=True) \n",
    "\n",
    "# # Najlepsze parametry i wynik\n",
    "# print(\"Najlepsze parametry:\", study.best_params)\n",
    "# print(\"Najlepsza dokładność:\", study.best_value)\n",
    "\n",
    "# ### dwa tygodnie więc lepiej aby te wartości stanowiły dobrą podstawę...\n",
    "# #Trial 76 finished with value:  0.9906666874885559 and parameters: {'num_filters1': 194, 'num_filters2': 167, 'num_filters3': 221, 'PCA_components': 383, 'l1_1': 1.4917571854023011e-06, 'l2_1': 0.0003844462705458024,  'l1_2': 0.0011921068803372,     'l2_2': 0.00021948428596782946, 'l1_3': 0.05677951548917238,    'l2_3': 7.714986268695782e-05,  'activation': 'relu', 'optimizer': 'AdamW', 'lr_initial': 0.006869840110235172, 'reduce_lr_factor': 0.2, 'reduce_lr_patience': 7, 'reduce_lr_min_lr': 2.028747844465778e-06,  'epochs': 51, 'batch_size': 479}.\n",
    "# #Trial 99 finished with value:  0.9911666512489319 and parameters: {'num_filters1': 222, 'num_filters2': 220, 'num_filters3': 202, 'PCA_components': 367, 'l1_1': 4.875844948451946e-06,  'l2_1': 0.00014963179483695857, 'l1_2': 2.3622464527905993e-06, 'l2_2': 0.0007506481920246097,  'l1_3': 0.030678868126237845,   'l2_3': 0.00016514043221099142, 'activation': 'mish', 'optimizer': 'AdamW', 'lr_initial': 0.00653453290497133,  'reduce_lr_factor': 0.1, 'reduce_lr_patience': 7, 'reduce_lr_min_lr': 2.8941869280860333e-06, 'epochs': 54, 'batch_size': 331}.\n",
    "# #Trial 108 finished with value: 0.9915000200271606 and parameters: {'num_filters1': 205, 'num_filters2': 206, 'num_filters3': 220, 'PCA_components': 370, 'l1_1': 9.95600828812184e-06,   'l2_1': 4.680137051239973e-05,  'l1_2': 4.9076000996726795e-06, 'l2_2': 8.638060092445147e-05,  'l1_3': 0.0361709248993415,     'l2_3': 0.0007397174884371887,  'activation': 'mish', 'optimizer': 'AdamW', 'lr_initial': 0.006269166650314777, 'reduce_lr_factor': 0.2, 'reduce_lr_patience': 7, 'reduce_lr_min_lr': 5.203896150606987e-06,  'epochs': 62, 'batch_size': 239}.\n",
    "# #Trial 121 finished with value: 0.9904166460037231 and parameters: {'num_filters1': 189, 'num_filters2': 200, 'num_filters3': 220, 'PCA_components': 387, 'l1_1': 8.32443244291399e-05,   'l2_1': 5.963850113018811e-05,  'l1_2': 4.8017415472934674e-06, 'l2_2': 3.9423405128005956e-05, 'l1_3': 0.00047971791859799064, 'l2_3': 0.0014900662405900767,  'activation': 'mish', 'optimizer': 'AdamW', 'lr_initial': 0.006533479568732247, 'reduce_lr_factor': 0.4, 'reduce_lr_patience': 6, 'reduce_lr_min_lr': 7.315164005922789e-06,  'epochs': 58, 'batch_size': 249}.\n",
    "# #Trial 134 finished with value: 0.9904166460037231 and parameters: {'num_filters1': 180, 'num_filters2': 196, 'num_filters3': 234, 'PCA_components': 390, 'l1_1': 4.148854564296224e-05,  'l2_1': 2.3209137723337733e-05, 'l1_2': 0.0009209306936723504,  'l2_2': 1.9816087702628798e-05, 'l1_3': 0.0008993453039409338,  'l2_3': 0.002218879345590759,   'activation': 'mish', 'optimizer': 'AdamW', 'lr_initial': 0.007404316715937198, 'reduce_lr_factor': 0.1, 'reduce_lr_patience': 7, 'reduce_lr_min_lr': 3.862546224445297e-07,  'epochs': 61, 'batch_size': 368}.\n",
    "# #Trial 151 finished with value: 0.9904166460037231 and parameters: {'num_filters1': 201, 'num_filters2': 189, 'num_filters3': 229, 'PCA_components': 403, 'l1_1': 6.15892270118e-05,      'l2_1': 1.6056284141459273e-05, 'l1_2': 0.0009167391639733724,  'l2_2': 1.4409315946656477e-05, 'l1_3': 0.0008899963895277467,  'l2_3': 0.005080838638011425,   'activation': 'mish', 'optimizer': 'AdamW', 'lr_initial': 0.007378956521980373, 'reduce_lr_factor': 0.1, 'reduce_lr_patience': 7, 'reduce_lr_min_lr': 1.9759552872681682e-07, 'epochs': 63, 'batch_size': 416}.\n",
    "# #Trial 153 finished with value: 0.9905833601951599 and parameters: {'num_filters1': 158, 'num_filters2': 190, 'num_filters3': 229, 'PCA_components': 405, 'l1_1': 3.317865892202326e-05,  'l2_1': 1.715760099034611e-05,  'l1_2': 0.00028475050803045533, 'l2_2': 7.144046413508896e-06,  'l1_3': 0.0010057548651594868,  'l2_3': 0.001544820248650564,   'activation': 'mish', 'optimizer': 'AdamW', 'lr_initial': 0.007667044780464368, 'reduce_lr_factor': 0.1, 'reduce_lr_patience': 7, 'reduce_lr_min_lr': 1.6284942102179344e-07, 'epochs': 64, 'batch_size': 420}.\n",
    "# #Trial 189 finished with value: 0.9904166460037231 and parameters: {'num_filters1': 187, 'num_filters2': 194, 'num_filters3': 191, 'PCA_components': 381, 'l1_1': 0.0001222508587314991,  'l2_1': 5.2900939483419044e-05, 'l1_2': 4.050810455502403e-05,  'l2_2': 0.00017281194315162931, 'l1_3': 0.0014341620209873955,  'l2_3': 0.0025511470455798512,  'activation': 'mish', 'optimizer': 'AdamW', 'lr_initial': 0.006996548564114207, 'reduce_lr_factor': 0.1, 'reduce_lr_patience': 6, 'reduce_lr_min_lr': 9.663271049317225e-07,  'epochs': 60, 'batch_size': 219}.\n",
    "# #Trial 205 finished with value: 0.9904999732971191 and parameters: {'num_filters1': 210, 'num_filters2': 189, 'num_filters3': 198, 'PCA_components': 483, 'l1_1': 8.253178154361272e-05,  'l2_1': 1.7866032331171518e-05, 'l1_2': 0.0008019764970918962,  'l2_2': 1.0316537375038554e-05, 'l1_3': 0.000838618983241391,   'l2_3': 0.008249547665798275,   'activation': 'mish', 'optimizer': 'AdamW', 'lr_initial': 0.006570979651986537, 'reduce_lr_factor': 0.1, 'reduce_lr_patience': 7, 'reduce_lr_min_lr': 2.6114120319881016e-07, 'epochs': 63, 'batch_size': 560}.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V2 zmina na dynamic PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import keras\n",
    "# from keras import layers\n",
    "# import tensorflow_probability as tfp\n",
    "# import optuna\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau \n",
    "\n",
    "# X_train_image, X_val_image, y_train_image, y_val_image = train_test_split(X_train, y_train_ENC, test_size=0.2, random_state=69)\n",
    "# X_train_image = X_train_image.astype('float32')\n",
    "# X_val_image = X_val_image.astype('float32')\n",
    "# X_train_image = np.expand_dims(X_train_image, axis=-1)  \n",
    "# X_val_image = np.expand_dims(X_val_image, axis=-1) \n",
    " \n",
    "# def objective(trial):\n",
    "#     # Przestrzeń hiperparametrów\n",
    "#     num_filters1 = trial.suggest_int(\"num_filters1\", 180, 230)    # Pierwsza warstwa Conv2d\n",
    "#     num_filters2 = trial.suggest_int(\"num_filters2\", 180, 230)    # Druga warstwa Conv2d\n",
    "#     num_filters3 = trial.suggest_int(\"num_filters3\", 180, 260)    # Trzecia warstwa Conv2d\n",
    "#     n_components = trial.suggest_int(\"PCA_components\", 350, 420)  # PCA\n",
    "    \n",
    "#     l1_1=trial.suggest_float('l1_1', 1e-6, 5e-3, log=True)\n",
    "#     l2_1=trial.suggest_float('l2_1', 5e-5, 5e-3, log=True)\n",
    "    \n",
    "#     l1_2=trial.suggest_float('l1_2', 1e-6, 1e-3, log=True)\n",
    "#     l2_2=trial.suggest_float('l2_2', 1e-6, 1e-5, log=True)\n",
    "\n",
    "#     l1_3=trial.suggest_float('l1_3', 1e-6, 1e-1, log=True)\n",
    "#     l2_3=trial.suggest_float('l2_3', 1e-6, 1e-1, log=True)\n",
    "    \n",
    "#     activation_functions = ['gelu', 'leaky_relu', 'silu', 'mish']\n",
    "#     activation = trial.suggest_categorical('activation', activation_functions)\n",
    "    \n",
    "    \n",
    "#     class DynamicPCA(keras.layers.Layer):\n",
    "#         def __init__(self, n_components, layer, update_freq=2, threshold=0.5, **kwargs):  \n",
    "#             super(DynamicPCA, self).__init__(**kwargs)\n",
    "#             self.n_components = n_components\n",
    "#             self.threshold = threshold\n",
    "#             self.layer = layer  \n",
    "#             self.update_freq = update_freq\n",
    "#             self.val_loss = None\n",
    "#             self.eigenvectors = None\n",
    "#             self.epoch_count = 0\n",
    "\n",
    "#         def build(self, input_shape):\n",
    "#             self.eigenvectors = self.add_weight(\n",
    "#                 shape=(input_shape[-1], self.n_components),\n",
    "#                 initializer=\"zeros\",\n",
    "#                 trainable=True,\n",
    "#             )\n",
    "\n",
    "#         def call(self, inputs):\n",
    "#             self.epoch_count += 1\n",
    "#             if (self.val_loss is not None and \n",
    "#                 self.val_loss < self.threshold and \n",
    "#                 self.epoch_count % self.update_freq == 0):\n",
    "#                 print(\"DynamicPCA: Aktualizacja wektorów własnych!\")\n",
    "#                 print(f\"val_loss: {self.val_loss}, threshold: {self.threshold}, epoch_count: {self.epoch_count}, update_freq: {self.update_freq}\")\n",
    "                \n",
    "#                 # Pobierz wagi bezpośrednio z warstwy\n",
    "#                 weights = self.layer.get_weights()  \n",
    "#                 flat_weights = tf.concat([tf.reshape(w, [-1]) for w in weights], axis=0)\n",
    "#                 # Normalizacja wag\n",
    "#                 flat_weights = tf.math.l2_normalize(flat_weights)\n",
    "#                 # Obliczanie nowych wektorów własnych\n",
    "#                 new_eigenvectors = self.calculate_pca(flat_weights)\n",
    "#                 # Aktualizacja wag (wektorów własnych)\n",
    "#                 self.eigenvectors.assign(new_eigenvectors)\n",
    "\n",
    "#             # Mnożenie przez wektory własne\n",
    "#             output = tf.matmul(inputs, self.eigenvectors)\n",
    "#             return output\n",
    "\n",
    "#         def calculate_pca(self, inputs):\n",
    "#             print(flat_weights.shape)\n",
    "#             # Obliczanie macierzy kowariancji\n",
    "#             covariance_matrix = tf.linalg.cov(inputs)  \n",
    "#             # Wektory i wartości własne\n",
    "#             eigenvalues, eigenvectors = tf.linalg.eigh(covariance_matrix)\n",
    "#             sorted_indices = tf.argsort(eigenvalues, direction='DESCENDING')\n",
    "#             eigenvectors = tf.gather(eigenvectors, sorted_indices, axis=1)\n",
    "#             return eigenvectors[:, :self.n_components]\n",
    "\n",
    "#     class MyCallback(keras.callbacks.Callback):\n",
    "#         def on_epoch_end(self, epoch, logs=None):\n",
    "#             pca_layer = self.model.get_layer('dynamic_pca')\n",
    "#             pca_layer.val_loss = logs.get('val_loss')\n",
    "#             print(logs.get('val_loss'))\n",
    "\n",
    "#     # Definiowanie wejścia\n",
    "#     image_input = keras.Input(shape=X_train_image.shape[1:])  \n",
    "\n",
    "#     # Warstwy konwolucyjne\n",
    "#     conv1 = keras.layers.Conv2D(num_filters1, kernel_size=(2, 2), activation=activation)(image_input)\n",
    "#     pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "#     conv2 = keras.layers.Conv2D(num_filters2, kernel_size=(2, 2), activation=activation)(pool1)\n",
    "#     pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "#     conv3 = keras.layers.Conv2D(num_filters3, kernel_size=(2, 2), activation=activation)(pool2)\n",
    "#     pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "#     flat_cnn = keras.layers.Flatten()(pool3)\n",
    "\n",
    "#     # Dense 1\n",
    "#     dense = keras.layers.Dense(units=trial.suggest_int('dense_units_1', 60, 240), activation=activation)(flat_cnn) \n",
    "#     dense = keras.layers.Dropout(rate=trial.suggest_float('dropout_rate_1', 0.01, 0.75))(dense)\n",
    "\n",
    "#     # Warstwa DynamicPCA \n",
    "#     pca_output = DynamicPCA(n_components=n_components, layer=conv3, name='dynamic_pca', threshold=1.25)(flat_cnn)  \n",
    "    \n",
    "#     merged = keras.layers.Concatenate()([dense, pca_output])\n",
    "\n",
    "#     dense2 = keras.layers.Dense(units=trial.suggest_int('dense_units_2', 60, 240), activation=activation)(merged)  \n",
    "#     dense2 = keras.layers.Dropout(rate=trial.suggest_float('dropout_rate_2', 0.01, 0.75))(dense2)\n",
    "\n",
    "#     # Output (klasyfikacja)\n",
    "#     outputs = keras.layers.Dense(10, activation='softmax')(dense2)\n",
    "\n",
    "#     # Utworzenie modelu\n",
    "#     model = keras.Model(inputs=image_input, outputs=outputs)\n",
    "\n",
    "#     # Utworzenie modelu\n",
    "#     model = keras.Model(inputs=image_input, outputs=outputs)\n",
    "#     #model.summary()\n",
    "#     tf.keras.utils.plot_model(model, show_shapes=True, to_file='model.png')\n",
    "    \n",
    "\n",
    "#     # Optymalizator\n",
    "#     optimizer_name = trial.suggest_categorical('optimizer', ['AdamW'])\n",
    "#     optimizer_class = getattr(tf.keras.optimizers, optimizer_name)\n",
    "    \n",
    "#     # Początkową wartość learning rate\n",
    "#     lr_initial = trial.suggest_float(\"lr_initial\", 5e-3, 1e-1, log=True)\n",
    "#     optimizer = optimizer_class(learning_rate=lr_initial)  \n",
    "\n",
    "#     ## Kompilacja modelu\n",
    "#     model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "#     # Early Stopping\n",
    "#     early_stopping = EarlyStopping(monitor='categorical_accuracy', patience=10, start_from_epoch=8, min_delta=0.0001)\n",
    "    \n",
    "#     # ReduceLROnPlateau\n",
    "#     reduce_lr = ReduceLROnPlateau(\n",
    "#         monitor='val_loss',\n",
    "#         factor=trial.suggest_float(\"reduce_lr_factor\", 0.1, 0.5, step=0.1),\n",
    "#         patience=trial.suggest_int(\"reduce_lr_patience\", 4, 8),\n",
    "#         min_lr=trial.suggest_float(\"reduce_lr_min_lr\", 1e-7, 1e-5, log=True)\n",
    "#     )\n",
    "    \n",
    "#     # Trenowanie i ocena modelu\n",
    "#     history = model.fit(X_train_image, y_train_image,\n",
    "#                         epochs=trial.suggest_int('epochs', 20, 80),\n",
    "#                         batch_size=trial.suggest_int('batch_size', 164, 768),\n",
    "#                         validation_data=(X_val_image, y_val_image),\n",
    "#                         validation_freq=1,\n",
    "#                         callbacks=[early_stopping, reduce_lr, MyCallback()]\n",
    "#                         )\n",
    "    \n",
    "#     accuracy = history.history['val_categorical_accuracy'][-1]\n",
    "\n",
    "#     return accuracy\n",
    "\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler())\n",
    "# study.optimize(objective, n_trials=600, n_jobs=1, gc_after_trial=True) \n",
    "\n",
    "# # Najlepsze parametry i wynik\n",
    "# print(\"Najlepsze parametry:\", study.best_params)\n",
    "# print(\"Najlepsza dokładność:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model bazujący na dwóch potokach danych. Surowych przechodzących przez Conv2d, oraz LSTM dla danych z HOG i Gabor. Wykorzystanie mechanizmu atencji. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 07:01:26,698] A new study created in memory with name: no-name-66981460-1c1f-416d-b118-29fc99a84ce2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - categorical_accuracy: 0.1061 - loss: 3.0710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 07:20:41,161] Trial 0 finished with value: 0.23383332788944244 and parameters: {'units_1': 71, 'units_2': 203, 'units_3': 233, 'l1_1': 8.332538194302532e-06, 'l2_1': 1.673004411434536e-05, 'l1_2': 0.06060377837807155, 'l2_2': 5.788691679832049e-06, 'l1_3': 0.01755069426269973, 'l2_3': 2.5481486473728422e-05, 'num_filters1': 199, 'num_filters2': 243, 'num_filters3': 302, 'activation': 'mish', 'dense_units_1': 190, 'dropout_rate_1': 0.3456766895750118, 'reduce_lr_factor': 0.2, 'reduce_lr_patience': 5, 'reduce_lr_min_lr': 1.1419098395215735e-06, 'optimizer': 'AdamW', 'lr_initial': 0.03180880541145646, 'epochs': 77, 'batch_size': 460}. Best is trial 0 with value: 0.23383332788944244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 3.0714, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - categorical_accuracy: 0.2785 - loss: 110989.4219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 07:40:09,839] Trial 1 finished with value: 0.38183334469795227 and parameters: {'units_1': 117, 'units_2': 211, 'units_3': 207, 'l1_1': 4.992396040062919e-06, 'l2_1': 0.0006520491498335392, 'l1_2': 0.0059899314151643495, 'l2_2': 1.1790242236936085e-06, 'l1_3': 4.4741605088945485e-05, 'l2_3': 0.03352879640954223, 'num_filters1': 183, 'num_filters2': 170, 'num_filters3': 249, 'activation': 'leaky_relu', 'dense_units_1': 145, 'dropout_rate_1': 0.04391848705935251, 'reduce_lr_factor': 0.30000000000000004, 'reduce_lr_patience': 5, 'reduce_lr_min_lr': 2.6671887408463875e-07, 'optimizer': 'Lion', 'lr_initial': 0.01763159844765703, 'epochs': 34, 'batch_size': 243}. Best is trial 1 with value: 0.38183334469795227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 111295.4531, Final val_accuracy: 0.2774\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - categorical_accuracy: 0.1424 - loss: 411254.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 08:10:42,934] Trial 2 finished with value: 0.1900833398103714 and parameters: {'units_1': 170, 'units_2': 96, 'units_3': 260, 'l1_1': 0.013309056238441001, 'l2_1': 0.003034661999948193, 'l1_2': 6.232896611625731e-05, 'l2_2': 0.007215305207338635, 'l1_3': 8.271807813382064e-05, 'l2_3': 1.6497058787789868e-06, 'num_filters1': 210, 'num_filters2': 223, 'num_filters3': 172, 'activation': 'leaky_relu', 'dense_units_1': 72, 'dropout_rate_1': 0.6532353232397079, 'reduce_lr_factor': 0.30000000000000004, 'reduce_lr_patience': 4, 'reduce_lr_min_lr': 7.5836667474478734e-06, 'optimizer': 'Lion', 'lr_initial': 0.060427159169420715, 'epochs': 51, 'batch_size': 566}. Best is trial 1 with value: 0.38183334469795227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 409482.1250, Final val_accuracy: 0.1397\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - categorical_accuracy: 0.9308 - loss: 0.2924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 09:08:48,578] Trial 3 finished with value: 0.9336666464805603 and parameters: {'units_1': 171, 'units_2': 192, 'units_3': 287, 'l1_1': 5.2630767137523355e-05, 'l2_1': 8.074462175388115e-05, 'l1_2': 2.885274905152446e-06, 'l2_2': 1.074881186301541e-05, 'l1_3': 0.0025393322636569275, 'l2_3': 0.004053255903922524, 'num_filters1': 213, 'num_filters2': 190, 'num_filters3': 290, 'activation': 'silu', 'dense_units_1': 164, 'dropout_rate_1': 0.34775343738204895, 'reduce_lr_factor': 0.30000000000000004, 'reduce_lr_patience': 7, 'reduce_lr_min_lr': 1.3300863244559678e-07, 'optimizer': 'AdamW', 'lr_initial': 0.01367019327597947, 'epochs': 61, 'batch_size': 515}. Best is trial 3 with value: 0.9336666464805603.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 0.2910, Final val_accuracy: 0.9284\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - categorical_accuracy: 0.1061 - loss: 25.8416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 09:42:54,902] Trial 4 finished with value: 0.1067499965429306 and parameters: {'units_1': 192, 'units_2': 155, 'units_3': 231, 'l1_1': 8.892796462414808e-05, 'l2_1': 0.002285261661252785, 'l1_2': 4.676026746824984e-06, 'l2_2': 0.013077562320953934, 'l1_3': 9.880549036438746e-05, 'l2_3': 1.4333429601379459e-05, 'num_filters1': 171, 'num_filters2': 160, 'num_filters3': 300, 'activation': 'gelu', 'dense_units_1': 230, 'dropout_rate_1': 0.27123844308338035, 'reduce_lr_factor': 0.2, 'reduce_lr_patience': 4, 'reduce_lr_min_lr': 5.885234415116429e-07, 'optimizer': 'AdamW', 'lr_initial': 0.055282502397295055, 'epochs': 37, 'batch_size': 197}. Best is trial 3 with value: 0.9336666464805603.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 25.8419, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - categorical_accuracy: 0.2532 - loss: 3529.2725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 10:11:45,600] Trial 5 finished with value: 0.2632499933242798 and parameters: {'units_1': 106, 'units_2': 183, 'units_3': 130, 'l1_1': 0.0001755708096231749, 'l2_1': 0.00031546403009977624, 'l1_2': 1.731685142981664e-05, 'l2_2': 0.021995030365642255, 'l1_3': 5.3388864921303135e-05, 'l2_3': 0.044794363547474805, 'num_filters1': 140, 'num_filters2': 200, 'num_filters3': 217, 'activation': 'leaky_relu', 'dense_units_1': 106, 'dropout_rate_1': 0.15763318949659536, 'reduce_lr_factor': 0.2, 'reduce_lr_patience': 5, 'reduce_lr_min_lr': 9.145340534048816e-07, 'optimizer': 'AdamW', 'lr_initial': 0.0771270308258527, 'epochs': 68, 'batch_size': 690}. Best is trial 3 with value: 0.9336666464805603.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 3516.8032, Final val_accuracy: 0.2495\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - categorical_accuracy: 0.2209 - loss: 87.4215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 10:46:56,132] Trial 6 finished with value: 0.24941666424274445 and parameters: {'units_1': 185, 'units_2': 69, 'units_3': 159, 'l1_1': 0.0002230605120211702, 'l2_1': 0.05725451612113631, 'l1_2': 0.03846008233462915, 'l2_2': 0.027167901594837795, 'l1_3': 1.659379875849706e-05, 'l2_3': 0.00036497814338421933, 'num_filters1': 185, 'num_filters2': 189, 'num_filters3': 314, 'activation': 'leaky_relu', 'dense_units_1': 153, 'dropout_rate_1': 0.1777446701369334, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 6, 'reduce_lr_min_lr': 6.5328999650196735e-06, 'optimizer': 'AdamW', 'lr_initial': 0.01560507541852592, 'epochs': 61, 'batch_size': 589}. Best is trial 3 with value: 0.9336666464805603.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 87.3880, Final val_accuracy: 0.2237\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - categorical_accuracy: 0.1061 - loss: 124.3370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 11:40:56,743] Trial 7 finished with value: 0.1067499965429306 and parameters: {'units_1': 102, 'units_2': 209, 'units_3': 92, 'l1_1': 0.006574383580908668, 'l2_1': 0.002411316631133925, 'l1_2': 0.0005998916919577764, 'l2_2': 0.00017177131287856537, 'l1_3': 7.72916590729284e-06, 'l2_3': 4.502622100554479e-05, 'num_filters1': 142, 'num_filters2': 202, 'num_filters3': 245, 'activation': 'mish', 'dense_units_1': 110, 'dropout_rate_1': 0.4090310144898697, 'reduce_lr_factor': 0.4, 'reduce_lr_patience': 7, 'reduce_lr_min_lr': 1.9049505662386608e-07, 'optimizer': 'Lion', 'lr_initial': 0.007075121149636369, 'epochs': 87, 'batch_size': 522}. Best is trial 3 with value: 0.9336666464805603.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 124.3373, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - categorical_accuracy: 0.1061 - loss: 51649.7305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 12:54:23,880] Trial 8 finished with value: 0.11100000143051147 and parameters: {'units_1': 176, 'units_2': 216, 'units_3': 157, 'l1_1': 0.00025066846067250856, 'l2_1': 0.0010463431811569975, 'l1_2': 0.00035085950211380607, 'l2_2': 0.0007011647409210816, 'l1_3': 0.0006210846082886129, 'l2_3': 0.0014929296903863167, 'num_filters1': 162, 'num_filters2': 226, 'num_filters3': 293, 'activation': 'mish', 'dense_units_1': 102, 'dropout_rate_1': 0.31776586241015486, 'reduce_lr_factor': 0.4, 'reduce_lr_patience': 5, 'reduce_lr_min_lr': 5.8921634016845625e-06, 'optimizer': 'Lion', 'lr_initial': 0.07256119961568455, 'epochs': 88, 'batch_size': 456}. Best is trial 3 with value: 0.9336666464805603.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 51649.8359, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - categorical_accuracy: 0.1824 - loss: 1251.9824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 13:05:29,894] Trial 9 finished with value: 0.2549166679382324 and parameters: {'units_1': 92, 'units_2': 123, 'units_3': 172, 'l1_1': 1.6111283988361753e-06, 'l2_1': 2.532375269856434e-05, 'l1_2': 0.0027919970138107486, 'l2_2': 0.00013690520274522823, 'l1_3': 0.001082327014978238, 'l2_3': 0.0005318944616974323, 'num_filters1': 123, 'num_filters2': 141, 'num_filters3': 174, 'activation': 'leaky_relu', 'dense_units_1': 238, 'dropout_rate_1': 0.02307391160581352, 'reduce_lr_factor': 0.1, 'reduce_lr_patience': 8, 'reduce_lr_min_lr': 2.7868766996379303e-07, 'optimizer': 'AdamW', 'lr_initial': 0.03876957763236066, 'epochs': 32, 'batch_size': 689}. Best is trial 3 with value: 0.9336666464805603.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 1249.6062, Final val_accuracy: 0.1811\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - categorical_accuracy: 0.9605 - loss: 0.2408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 13:54:12,165] Trial 10 finished with value: 0.9642500281333923 and parameters: {'units_1': 149, 'units_2': 247, 'units_3': 306, 'l1_1': 0.0799412713775556, 'l2_1': 3.614192917192245e-06, 'l1_2': 1.1361011682562603e-06, 'l2_2': 1.8969459797284842e-05, 'l1_3': 0.07533883762311577, 'l2_3': 0.0054847779478560945, 'num_filters1': 220, 'num_filters2': 173, 'num_filters3': 273, 'activation': 'silu', 'dense_units_1': 187, 'dropout_rate_1': 0.5449669316105996, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 9, 'reduce_lr_min_lr': 1.0813255848748781e-07, 'optimizer': 'AdamW', 'lr_initial': 0.008112590674918223, 'epochs': 50, 'batch_size': 323}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 0.2298, Final val_accuracy: 0.9643\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - categorical_accuracy: 0.9596 - loss: 0.2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 14:42:31,551] Trial 11 finished with value: 0.9581666588783264 and parameters: {'units_1': 148, 'units_2': 255, 'units_3': 314, 'l1_1': 0.0449187883970396, 'l2_1': 2.1868180064190156e-06, 'l1_2': 1.6561130244722797e-06, 'l2_2': 1.870782080615788e-05, 'l1_3': 0.0975608364508931, 'l2_3': 0.0046636419609060375, 'num_filters1': 219, 'num_filters2': 175, 'num_filters3': 271, 'activation': 'silu', 'dense_units_1': 185, 'dropout_rate_1': 0.5358964029606934, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 9, 'reduce_lr_min_lr': 1.1372081248378972e-07, 'optimizer': 'AdamW', 'lr_initial': 0.007657232301279919, 'epochs': 49, 'batch_size': 337}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 0.2033, Final val_accuracy: 0.9582\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - categorical_accuracy: 0.9479 - loss: 0.2549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 15:27:39,562] Trial 12 finished with value: 0.9496666789054871 and parameters: {'units_1': 137, 'units_2': 254, 'units_3': 318, 'l1_1': 0.08330403079007158, 'l2_1': 1.0026493048016676e-06, 'l1_2': 1.4398683498355906e-06, 'l2_2': 3.213135346746718e-05, 'l1_3': 0.09670834639215671, 'l2_3': 0.007589696287380235, 'num_filters1': 212, 'num_filters2': 167, 'num_filters3': 275, 'activation': 'silu', 'dense_units_1': 198, 'dropout_rate_1': 0.5769330666906304, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 9, 'reduce_lr_min_lr': 1.188935301621066e-07, 'optimizer': 'AdamW', 'lr_initial': 0.005603522754412215, 'epochs': 46, 'batch_size': 285}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 0.2491, Final val_accuracy: 0.9484\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - categorical_accuracy: 0.8203 - loss: 0.9004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 16:07:18,236] Trial 13 finished with value: 0.9422500133514404 and parameters: {'units_1': 142, 'units_2': 250, 'units_3': 318, 'l1_1': 0.002909179836021078, 'l2_1': 1.634224404360466e-06, 'l1_2': 2.991880277422458e-05, 'l2_2': 3.383697516515297e-05, 'l1_3': 0.0906839881189634, 'l2_3': 0.00732334320152505, 'num_filters1': 197, 'num_filters2': 151, 'num_filters3': 222, 'activation': 'silu', 'dense_units_1': 196, 'dropout_rate_1': 0.5240413534766368, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 9, 'reduce_lr_min_lr': 4.1910774200295166e-07, 'optimizer': 'AdamW', 'lr_initial': 0.008762408823625816, 'epochs': 45, 'batch_size': 338}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 0.8633, Final val_accuracy: 0.8259\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - categorical_accuracy: 0.1061 - loss: 2.4007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 16:27:22,518] Trial 14 finished with value: 0.1067499965429306 and parameters: {'units_1': 148, 'units_2': 235, 'units_3': 281, 'l1_1': 0.054128225408631485, 'l2_1': 6.585832937179552e-06, 'l1_2': 1.173877818882694e-06, 'l2_2': 0.0015509799614303256, 'l1_3': 0.008312583914898239, 'l2_3': 0.0014443882612838247, 'num_filters1': 215, 'num_filters2': 178, 'num_filters3': 326, 'activation': 'silu', 'dense_units_1': 174, 'dropout_rate_1': 0.7169945160037989, 'reduce_lr_factor': 0.4, 'reduce_lr_patience': 8, 'reduce_lr_min_lr': 1.9698299996935055e-06, 'optimizer': 'AdamW', 'lr_initial': 0.010371634981596772, 'epochs': 20, 'batch_size': 365}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 2.4011, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - categorical_accuracy: 0.1061 - loss: 2.4933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 16:48:52,041] Trial 15 finished with value: 0.9420833587646484 and parameters: {'units_1': 155, 'units_2': 157, 'units_3': 283, 'l1_1': 0.0015598259275704498, 'l2_1': 4.60873569818219e-06, 'l1_2': 1.2158859432705427e-05, 'l2_2': 1.5911272047532472e-06, 'l1_3': 1.2772843425016182e-06, 'l2_3': 0.06240061196580539, 'num_filters1': 196, 'num_filters2': 213, 'num_filters3': 268, 'activation': 'silu', 'dense_units_1': 215, 'dropout_rate_1': 0.48640750444232456, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 8, 'reduce_lr_min_lr': 1.0247666015547222e-07, 'optimizer': 'AdamW', 'lr_initial': 0.005228166958204342, 'epochs': 56, 'batch_size': 372}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 2.4937, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - categorical_accuracy: 0.1061 - loss: 2.3647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 18:11:14,339] Trial 16 finished with value: 0.1067499965429306 and parameters: {'units_1': 127, 'units_2': 231, 'units_3': 251, 'l1_1': 0.03660320324926161, 'l2_1': 6.848577994219005e-05, 'l1_2': 5.47094417440071e-05, 'l2_2': 4.815543447006073e-05, 'l1_3': 0.01826645499750952, 'l2_3': 0.013716015154948873, 'num_filters1': 218, 'num_filters2': 180, 'num_filters3': 336, 'activation': 'gelu', 'dense_units_1': 136, 'dropout_rate_1': 0.6055502900965813, 'reduce_lr_factor': 0.4, 'reduce_lr_patience': 9, 'reduce_lr_min_lr': 3.1865006029802244e-06, 'optimizer': 'AdamW', 'lr_initial': 0.023263478001181392, 'epochs': 72, 'batch_size': 179}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 2.3651, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - categorical_accuracy: 0.1061 - loss: 2.3436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 18:46:54,291] Trial 17 finished with value: 0.47600001096725464 and parameters: {'units_1': 49, 'units_2': 181, 'units_3': 299, 'l1_1': 0.014762697675854811, 'l2_1': 4.359201810057344e-06, 'l1_2': 6.57844801012121e-06, 'l2_2': 7.378929370024489e-06, 'l1_3': 0.004802417443455097, 'l2_3': 0.0016809950154911338, 'num_filters1': 202, 'num_filters2': 257, 'num_filters3': 211, 'activation': 'silu', 'dense_units_1': 177, 'dropout_rate_1': 0.4854764246882011, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 8, 'reduce_lr_min_lr': 2.0655748902992018e-07, 'optimizer': 'AdamW', 'lr_initial': 0.009907480166681538, 'epochs': 41, 'batch_size': 289}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 2.3440, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - categorical_accuracy: 0.1061 - loss: 660.4066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 19:05:17,073] Trial 18 finished with value: 0.1067499965429306 and parameters: {'units_1': 155, 'units_2': 133, 'units_3': 260, 'l1_1': 0.0011617197439826527, 'l2_1': 0.02952108181928317, 'l1_2': 0.0001413212967594168, 'l2_2': 0.00236682054098326, 'l1_3': 0.03680730304191456, 'l2_3': 9.383516097948422e-05, 'num_filters1': 183, 'num_filters2': 152, 'num_filters3': 269, 'activation': 'silu', 'dense_units_1': 207, 'dropout_rate_1': 0.7139389366191096, 'reduce_lr_factor': 0.4, 'reduce_lr_patience': 9, 'reduce_lr_min_lr': 5.178694084351649e-07, 'optimizer': 'Lion', 'lr_initial': 0.00716202253818741, 'epochs': 24, 'batch_size': 408}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 660.4067, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - categorical_accuracy: 0.9392 - loss: 0.2980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 19:46:04,749] Trial 19 finished with value: 0.9433333277702332 and parameters: {'units_1': 125, 'units_2': 231, 'units_3': 199, 'l1_1': 0.022218270008648434, 'l2_1': 9.819847350139819e-05, 'l1_2': 1.1036801560884128e-06, 'l2_2': 8.271338474577003e-05, 'l1_3': 0.001629367317393596, 'l2_3': 0.015095429609805842, 'num_filters1': 220, 'num_filters2': 185, 'num_filters3': 238, 'activation': 'silu', 'dense_units_1': 129, 'dropout_rate_1': 0.43137346516384295, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 7, 'reduce_lr_min_lr': 3.448547282869822e-07, 'optimizer': 'AdamW', 'lr_initial': 0.011982433839025261, 'epochs': 52, 'batch_size': 292}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 0.2877, Final val_accuracy: 0.9419\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - categorical_accuracy: 0.1061 - loss: 2.3323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 20:51:20,745] Trial 20 finished with value: 0.3215833306312561 and parameters: {'units_1': 161, 'units_2': 252, 'units_3': 300, 'l1_1': 0.004865152521891479, 'l2_1': 1.3472641521749111e-05, 'l1_2': 4.725908414249016e-06, 'l2_2': 3.879706462325923e-06, 'l1_3': 0.022717700185016402, 'l2_3': 0.00015570401408618808, 'num_filters1': 172, 'num_filters2': 167, 'num_filters3': 267, 'activation': 'gelu', 'dense_units_1': 214, 'dropout_rate_1': 0.5527641965231409, 'reduce_lr_factor': 0.1, 'reduce_lr_patience': 9, 'reduce_lr_min_lr': 1.599050185165511e-07, 'optimizer': 'AdamW', 'lr_initial': 0.021904491534583174, 'epochs': 63, 'batch_size': 420}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 2.3327, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - categorical_accuracy: 0.1061 - loss: 2.6614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 21:11:48,801] Trial 21 finished with value: 0.1067499965429306 and parameters: {'units_1': 138, 'units_2': 255, 'units_3': 314, 'l1_1': 0.07800474971430404, 'l2_1': 1.161786631485052e-06, 'l1_2': 1.2190816057302256e-06, 'l2_2': 1.9124794359979865e-05, 'l1_3': 0.05389611813448656, 'l2_3': 0.004285358790895196, 'num_filters1': 207, 'num_filters2': 169, 'num_filters3': 279, 'activation': 'silu', 'dense_units_1': 196, 'dropout_rate_1': 0.6036406006477405, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 9, 'reduce_lr_min_lr': 1.018520481574511e-07, 'optimizer': 'AdamW', 'lr_initial': 0.005340346736707343, 'epochs': 45, 'batch_size': 288}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 2.6618, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - categorical_accuracy: 0.9501 - loss: 0.2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 21:59:22,403] Trial 22 finished with value: 0.9507499933242798 and parameters: {'units_1': 134, 'units_2': 236, 'units_3': 320, 'l1_1': 0.077042882713245, 'l2_1': 1.2474479688786062e-06, 'l1_2': 2.672833863474102e-06, 'l2_2': 0.0003766617325555096, 'l1_3': 0.0683471913714888, 'l2_3': 0.09628018468799235, 'num_filters1': 220, 'num_filters2': 156, 'num_filters3': 277, 'activation': 'silu', 'dense_units_1': 178, 'dropout_rate_1': 0.6394813160118011, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 8, 'reduce_lr_min_lr': 1.4457865361739395e-07, 'optimizer': 'AdamW', 'lr_initial': 0.007213412997730407, 'epochs': 49, 'batch_size': 239}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 0.2456, Final val_accuracy: 0.9507\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - categorical_accuracy: 0.1061 - loss: 24.0429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 22:41:54,696] Trial 23 finished with value: 0.9415000081062317 and parameters: {'units_1': 117, 'units_2': 231, 'units_3': 272, 'l1_1': 0.09828984293331952, 'l2_1': 2.5016106484953317e-06, 'l1_2': 8.848214922709122e-06, 'l2_2': 0.0004180508831364324, 'l1_3': 0.009378493777361493, 'l2_3': 0.06859491430976965, 'num_filters1': 220, 'num_filters2': 153, 'num_filters3': 262, 'activation': 'silu', 'dense_units_1': 174, 'dropout_rate_1': 0.6603741540287175, 'reduce_lr_factor': 0.4, 'reduce_lr_patience': 8, 'reduce_lr_min_lr': 1.932378288789084e-07, 'optimizer': 'AdamW', 'lr_initial': 0.007290494021895717, 'epochs': 54, 'batch_size': 229}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 24.0433, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - categorical_accuracy: 0.1084 - loss: 5.5593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 23:21:19,480] Trial 24 finished with value: 0.9421666860580444 and parameters: {'units_1': 132, 'units_2': 236, 'units_3': 295, 'l1_1': 0.023588578203398502, 'l2_1': 8.459208390365944e-06, 'l1_2': 3.013825123297668e-06, 'l2_2': 0.09147016088282739, 'l1_3': 0.03432670356716183, 'l2_3': 0.09971382836894728, 'num_filters1': 191, 'num_filters2': 145, 'num_filters3': 233, 'activation': 'silu', 'dense_units_1': 158, 'dropout_rate_1': 0.7493851824422104, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 8, 'reduce_lr_min_lr': 2.6233226345840687e-07, 'optimizer': 'AdamW', 'lr_initial': 0.008373310291746374, 'epochs': 47, 'batch_size': 334}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 5.5606, Final val_accuracy: 0.1042\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - categorical_accuracy: 0.9460 - loss: 0.2117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 23:53:32,192] Trial 25 finished with value: 0.9479166865348816 and parameters: {'units_1': 147, 'units_2': 219, 'units_3': 303, 'l1_1': 0.006660518306978212, 'l2_1': 3.067395088339557e-06, 'l1_2': 2.5060134583888146e-05, 'l2_2': 0.0002778543701909949, 'l1_3': 0.0002943634171445555, 'l2_3': 0.02341684844089055, 'num_filters1': 206, 'num_filters2': 175, 'num_filters3': 201, 'activation': 'silu', 'dense_units_1': 186, 'dropout_rate_1': 0.472620447925439, 'reduce_lr_factor': 0.4, 'reduce_lr_patience': 9, 'reduce_lr_min_lr': 1.3937219596854216e-07, 'optimizer': 'AdamW', 'lr_initial': 0.011071219461570038, 'epochs': 38, 'batch_size': 164}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 0.2055, Final val_accuracy: 0.9472\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - categorical_accuracy: 0.1061 - loss: 2.3034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-19 00:17:37,639] Trial 26 finished with value: 0.1067499965429306 and parameters: {'units_1': 163, 'units_2': 172, 'units_3': 238, 'l1_1': 0.0010956938661043649, 'l2_1': 3.220150931352529e-05, 'l1_2': 3.1087525457821306e-06, 'l2_2': 0.0008282096555288057, 'l1_3': 0.004621078617318151, 'l2_3': 0.00088026158300756, 'num_filters1': 203, 'num_filters2': 160, 'num_filters3': 257, 'activation': 'silu', 'dense_units_1': 223, 'dropout_rate_1': 0.6566113070542419, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 7, 'reduce_lr_min_lr': 8.901828489819665e-07, 'optimizer': 'Lion', 'lr_initial': 0.006591019372909006, 'epochs': 31, 'batch_size': 236}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 2.3037, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - categorical_accuracy: 0.1061 - loss: 11.4778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-19 01:05:38,742] Trial 27 finished with value: 0.1067499965429306 and parameters: {'units_1': 109, 'units_2': 243, 'units_3': 271, 'l1_1': 0.03265746286344527, 'l2_1': 2.628181219380924e-06, 'l1_2': 0.0012341012749143385, 'l2_2': 2.948603091411236e-06, 'l1_3': 0.08741617214805934, 'l2_3': 0.0030000465761593647, 'num_filters1': 159, 'num_filters2': 196, 'num_filters3': 315, 'activation': 'silu', 'dense_units_1': 167, 'dropout_rate_1': 0.5394169638303336, 'reduce_lr_factor': 0.4, 'reduce_lr_patience': 8, 'reduce_lr_min_lr': 1.5729944137065322e-07, 'optimizer': 'AdamW', 'lr_initial': 0.01743565681781683, 'epochs': 57, 'batch_size': 767}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 11.4781, Final val_accuracy: 0.1067\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - categorical_accuracy: 0.1061 - loss: 2.8715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-19 01:26:18,593] Trial 28 finished with value: 0.1067499965429306 and parameters: {'units_1': 88, 'units_2': 195, 'units_3': 320, 'l1_1': 0.009117276341294092, 'l2_1': 4.109106036052334e-05, 'l1_2': 0.0001140904454709037, 'l2_2': 1.5555652567527477e-05, 'l1_3': 0.011810719328485441, 'l2_3': 0.010853008256000617, 'num_filters1': 190, 'num_filters2': 159, 'num_filters3': 283, 'activation': 'gelu', 'dense_units_1': 183, 'dropout_rate_1': 0.6388305641457811, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 6, 'reduce_lr_min_lr': 3.44913330689104e-07, 'optimizer': 'AdamW', 'lr_initial': 0.013698261241938615, 'epochs': 50, 'batch_size': 334}. Best is trial 10 with value: 0.9642500281333923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val_loss: 2.8716, Final val_accuracy: 0.1067\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, GlobalAveragePooling1D, Permute, Flatten, Reshape, Conv2D, MaxPooling2D, Concatenate, Attention, Dense, LayerNormalization, ActivityRegularization, Dropout, GlobalAveragePooling2D, AveragePooling2D, AveragePooling1D, GlobalAveragePooling1D, GlobalMaxPool1D, GlobalMaxPool2D, MaxPool2D, SeparableConv1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import gc\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "X_train_reduced = np.load('X_train_reduced.npy')\n",
    "X_val_reduced = np.load('X_val_reduced.npy')\n",
    "y_train_filters = np.load('y_train_filters.npy')\n",
    "y_val_filters = np.load('y_val_filters.npy')\n",
    "\n",
    "X_train_reduced = X_train_reduced.reshape(X_train_reduced.shape[0], X_train_reduced.shape[1], 1)\n",
    "X_val_reduced = X_val_reduced.reshape(X_val_reduced.shape[0], X_val_reduced.shape[1], 1)\n",
    "\n",
    "X_train_image, X_val_image, y_train_image, y_val_image = train_test_split(X_train, y_train_ENC, test_size=0.2, random_state=69)\n",
    "X_train_image = X_train_image.astype('float32')\n",
    "X_val_image = X_val_image.astype('float32')\n",
    "X_train_image = np.expand_dims(X_train_image, axis=-1)  \n",
    "X_val_image = np.expand_dims(X_val_image, axis=-1) \n",
    " \n",
    "\n",
    "# # Sprawdzenie poprawności danych wejściowych\n",
    "# print(\"Kształt X_train_image:\", X_train_image.shape)\n",
    "# print(\"Kształt X_val_image:\", X_val_image.shape)\n",
    "# print(\"Kształt X_train_reduced:\", X_train_reduced.shape)\n",
    "# print(\"Kształt X_val_reduced:\", X_val_reduced.shape)\n",
    "\n",
    "# print(\"Kształt y_train_filters:\", y_train_filters.shape)\n",
    "# print(\"Kształt y_val_filters:\", y_val_filters.shape)\n",
    "# print(\"Kształt y_train_image:\", y_train_image.shape)\n",
    "# print(\"Kształt y_val_image:\", y_val_image.shape)\n",
    "\n",
    "# # Sprawdzenie typów danych\n",
    "# print(\"Typ danych X_train_image:\", X_train_image.dtype)\n",
    "# print(\"Typ danych X_val_image:\", X_val_image.dtype)\n",
    "# print(\"Typ danych X_train_reduced:\", X_train_reduced.dtype)\n",
    "# print(\"Typ danych X_val_reduced:\", X_val_reduced.dtype)\n",
    "# print(\"Typ danych y_train_filters:\", y_train_filters.dtype)\n",
    "# print(\"Typ danych y_val_filters:\", y_val_filters.dtype)\n",
    "# print(\"Typ danych y_train_image:\", y_train_image.dtype)\n",
    "# print(\"Typ danych y_val_image:\", y_val_image.dtype)\n",
    "\n",
    "def objective(trial):\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    # Dane wejściowe\n",
    "    image_input = Input(shape=X_train_image.shape[1:])\n",
    "    flattened_input = Input(shape=X_train_reduced.shape[1:])\n",
    "\n",
    "    ### Hiperparamatry \n",
    "    units1=trial.suggest_int('units_1', 48, 192)\n",
    "    units2=trial.suggest_int('units_2', 64, 256)\n",
    "    units3=trial.suggest_int('units_3', 92, 320)\n",
    "\n",
    "    l1_1=trial.suggest_float('l1_1', 1e-6, 1e-1, log=True)\n",
    "    l2_1=trial.suggest_float('l2_1', 1e-6, 1e-1, log=True)\n",
    "    \n",
    "    l1_2=trial.suggest_float('l1_2', 1e-6, 1e-1, log=True)\n",
    "    l2_2=trial.suggest_float('l2_2', 1e-6, 1e-1, log=True)\n",
    "\n",
    "    l1_3=trial.suggest_float('l1_3', 1e-6, 1e-1, log=True)\n",
    "    l2_3=trial.suggest_float('l2_3', 1e-6, 1e-1, log=True)\n",
    "    \n",
    "    filters1 = trial.suggest_int(\"num_filters1\", 120, 220)    # Pierwsza warstwa Conv2d\n",
    "    filters2 = trial.suggest_int(\"num_filters2\", 140, 260)    # Druga warstwa Conv2d\n",
    "    filters3 = trial.suggest_int(\"num_filters3\", 160, 340)    # Trzecia warstwa Conv2d\n",
    "\n",
    "    activation_functions = ['gelu', 'leaky_relu', 'silu', 'mish']\n",
    "    activation = trial.suggest_categorical('activation', activation_functions)\n",
    "\n",
    "    ###################\n",
    "    # Gałąź SeparableConv1D\n",
    "        ## Pierwsza warstwa\n",
    "    Sep_Conv1D_1 = SeparableConv1D(units1,\n",
    "                kernel_size = 2,\n",
    "                padding = 'same',\n",
    "                activation = activation\n",
    "                )(flattened_input)\n",
    "    \n",
    "        ## Druga warstwa\n",
    "    Sep_Conv1D_2 = SeparableConv1D(units2,\n",
    "                kernel_size = 2,\n",
    "                padding = 'same',\n",
    "                activation = activation\n",
    "                )(Sep_Conv1D_1)\n",
    "\n",
    "        ## Trzecia warstwa\n",
    "    Sep_Conv1D_3 = SeparableConv1D(units3,\n",
    "                kernel_size = 2,\n",
    "                padding = 'same',\n",
    "                activation = activation\n",
    "                )(Sep_Conv1D_2)\n",
    "\n",
    "    ## Pooling \n",
    "    Sep_pool_Conv1D = GlobalAveragePooling1D(\n",
    "                                       )(Sep_Conv1D_3) \n",
    "    #print(\"Global Average Pooling1D for Conv1D:\", Sep_pool_Conv1D)\n",
    "\n",
    "    # Gałąź Conv2D\n",
    "        ## Pierwsza warstwa\n",
    "    conv1 = Conv2D(filters1,\n",
    "                   kernel_size=(2, 2),\n",
    "                   kernel_regularizer=tf.keras.regularizers.l2(l2_1),\n",
    "                   bias_regularizer=tf.keras.regularizers.l1(l1_1),\n",
    "                   activation=activation,\n",
    "                   )(image_input)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        ## Druga warstwa\n",
    "    conv2 = Conv2D(filters2,\n",
    "                   kernel_size=(2, 2),\n",
    "                   kernel_regularizer=tf.keras.regularizers.l2(l2_2),\n",
    "                   bias_regularizer=tf.keras.regularizers.l1(l1_2),\n",
    "                   activation=activation,\n",
    "                   )(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        ## Trzecia warstwa\n",
    "    conv3 = Conv2D(filters3,\n",
    "                kernel_size=(2, 2),\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l2_3),\n",
    "                bias_regularizer=tf.keras.regularizers.l1(l1_3),\n",
    "                activation=activation\n",
    "                )(pool2)\n",
    "    \n",
    "    pool2 = MaxPool2D(pool_size=(3, 3)\n",
    "                        )(conv3)  \n",
    "    \n",
    "    flat_cnn = Flatten()(pool2)\n",
    "    #print(\"flat_cnn shape:\", flat_cnn)\n",
    "    \n",
    "    # Połączenie gałęzi\n",
    "    merged = Concatenate()([Sep_pool_Conv1D, flat_cnn])\n",
    "    #print(\"merged shape:\", merged)\n",
    "    merged = Reshape((merged.shape[1], 1))(merged)\n",
    "    #print(\"Reshape shape:\", merged)\n",
    "    \n",
    "    # Attention Layer\n",
    "    attention_output = Attention()([merged, merged])\n",
    "    attention_output = Reshape((attention_output.shape[1],))(attention_output)\n",
    "    \n",
    "    # Dense\n",
    "    dense = Dense(units=trial.suggest_int('dense_units_1', 60, 240), activation=activation)(attention_output)\n",
    "    dense = Dropout(rate=trial.suggest_float('dropout_rate_1', 0.01, 0.75))(dense)\n",
    "\n",
    "    #Output\n",
    "    output = Dense(10, activation='softmax')(dense)\n",
    "    model = Model(inputs=[image_input, flattened_input], outputs=output)\n",
    "    \n",
    "    tf.keras.utils.plot_model(model, show_shapes=True, to_file='model.png')\n",
    "    #model.summary()\n",
    "    \n",
    "    # ReduceLROnPlateau\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=trial.suggest_float(\"reduce_lr_factor\", 0.1, 0.5, step=0.1),\n",
    "        patience=trial.suggest_int(\"reduce_lr_patience\", 4, 9),\n",
    "        min_lr=trial.suggest_float(\"reduce_lr_min_lr\", 1e-7, 1e-5, log=True)\n",
    "    )\n",
    "\n",
    "    # Optymalizator\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['AdamW', 'Lion'])\n",
    "    optimizer_class = getattr(tf.keras.optimizers, optimizer_name)\n",
    "    \n",
    "    # Początkową wartość learning rate\n",
    "    lr_initial = trial.suggest_float(\"lr_initial\", 5e-3, 1e-1, log=True)\n",
    "    optimizer = optimizer_class(learning_rate=lr_initial)  \n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, start_from_epoch=8, min_delta=0.0001)\n",
    "    #tensorboard = TensorBoard(log_dir='./logs')\n",
    "\n",
    "    # Trenowanie modelu\n",
    "    history = model.fit(\n",
    "        [X_train_image, X_train_reduced], \n",
    "        y_train_filters,\n",
    "        epochs=trial.suggest_int('epochs', 20, 90),\n",
    "        batch_size=trial.suggest_int('batch_size', 164, 768),\n",
    "        validation_data=([X_val_image, X_val_reduced], y_val_filters),\n",
    "        verbose=0,\n",
    "        callbacks=[early_stopping, reduce_lr],# , tensorboard\n",
    "    )\n",
    "\n",
    "    best_val_accuracy = max(history.history['val_categorical_accuracy'])\n",
    "\n",
    "    # Ewaluacja modelu\n",
    "    loss, accuracy = model.evaluate([X_val_image, X_val_reduced], y_val_filters, verbose=1)\n",
    "    print(f\"Final val_loss: {loss:.4f}, Final val_accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    del model\n",
    "    return best_val_accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=200, n_jobs=1, gc_after_trial=True) ## Czy keras działa na wszystkich wątkach, ale optuna na pojedynczym. \n",
    "\n",
    "\n",
    "# Najlepsze parametry i wynik\n",
    "print(\"Najlepsze parametry:\", study.best_params)\n",
    "print(\"Najlepsza dokładność:\", study.best_value)\n",
    "\n",
    "#[I 2024-10-07 13:19:36,166] Trial 13 finished with value: 0.9700000286102295 and parameters: {'units_1': 92, 'units_2': 161, 'units_3': 117, 'l1_1': 0.0008839107419295125, 'l2_1': 1.154687911591668e-06, 'l1_2': 0.006313924135568636, 'l2_2': 6.780100126072228e-06, 'l1_3': 0.003353325847224238, 'l2_3': 5.4329911159199266e-05, 'conv2d_filters_1': 71, 'conv2d_filters_2': 56, 'conv2d_filters_3': 239, 'dense_units_1': 118, 'dropout_rate_4': 0.24924760076872401, 'reduce_lr_factor': 0.9, 'reduce_lr_patience': 2, 'reduce_lr_min_lr': 1.2116979296707788e-05, 'optimizer': 'AdamW', 'lr_initial': 0.005150547498928084, 'epochs': 62, 'batch_size': 1918}. Best is trial 12 with value: 0.9774166941642761."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
