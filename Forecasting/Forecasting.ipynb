{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "528b018a-b49b-4033-8b60-2465aa3f3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta,date\n",
    "\n",
    "# \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_palette('icefire_r', 2)\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "#Przetwarzanie\n",
    "\n",
    "# Baza danych g√≥wnych do nauki modelu\n",
    "train = pd.read_csv(\"train.csv\") \n",
    "# Baza danych Titanica do sprawdzenia modelu\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2587595f-4bf6-431e-94bb-d61499e6f3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date    country         store  \\\n",
       "0   0  2017-01-01  Argentina  Kaggle Learn   \n",
       "1   1  2017-01-01  Argentina  Kaggle Learn   \n",
       "2   2  2017-01-01  Argentina  Kaggle Learn   \n",
       "3   3  2017-01-01  Argentina  Kaggle Learn   \n",
       "4   4  2017-01-01  Argentina  Kaggle Learn   \n",
       "\n",
       "                                          product  num_sold  \n",
       "0               Using LLMs to Improve Your Coding        63  \n",
       "1                   Using LLMs to Train More LLMs        66  \n",
       "2  Using LLMs to Win Friends and Influence People         9  \n",
       "3      Using LLMs to Win More Kaggle Competitions        59  \n",
       "4                      Using LLMs to Write Better        49  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "363ab997-3237-4e0d-909a-db173f2c1d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136950</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136951</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136952</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136953</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136954</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id        date    country         store  \\\n",
       "0  136950  2022-01-01  Argentina  Kaggle Learn   \n",
       "1  136951  2022-01-01  Argentina  Kaggle Learn   \n",
       "2  136952  2022-01-01  Argentina  Kaggle Learn   \n",
       "3  136953  2022-01-01  Argentina  Kaggle Learn   \n",
       "4  136954  2022-01-01  Argentina  Kaggle Learn   \n",
       "\n",
       "                                          product  \n",
       "0               Using LLMs to Improve Your Coding  \n",
       "1                   Using LLMs to Train More LLMs  \n",
       "2  Using LLMs to Win Friends and Influence People  \n",
       "3      Using LLMs to Win More Kaggle Competitions  \n",
       "4                      Using LLMs to Write Better  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ddccef-88c9-40e4-ba9c-58e5660b7435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "date        0\n",
      "country     0\n",
      "store       0\n",
      "product     0\n",
      "num_sold    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.isnull(train).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2069e7-38bd-4dcf-a7de-54225a9805f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id         0\n",
      "date       0\n",
      "country    0\n",
      "store      0\n",
      "product    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.isnull(test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16b9301-440d-42fb-80b9-47f45aa45db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value counts and percentages for column country:\n",
      "country\n",
      "Argentina    20.0\n",
      "Canada       20.0\n",
      "Estonia      20.0\n",
      "Japan        20.0\n",
      "Spain        20.0\n",
      "Name: country, dtype: float64\n",
      "Unique value counts and percentages for column store:\n",
      "store\n",
      "Kagglazon       33.333333\n",
      "Kaggle Learn    33.333333\n",
      "Kaggle Store    33.333333\n",
      "Name: store, dtype: float64\n",
      "Unique value counts and percentages for column product:\n",
      "product\n",
      "Using LLMs to Improve Your Coding                 20.0\n",
      "Using LLMs to Train More LLMs                     20.0\n",
      "Using LLMs to Win Friends and Influence People    20.0\n",
      "Using LLMs to Win More Kaggle Competitions        20.0\n",
      "Using LLMs to Write Better                        20.0\n",
      "Name: product, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cols= ['country', 'store', 'product' ]\n",
    "for col in cols:\n",
    "  df_grouped = train.groupby(col)[col].count()\n",
    "  df_grouped = df_grouped / train[col].count() * 100\n",
    "  print(f\"Unique value counts and percentages for column {col}:\")\n",
    "  print(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed2e7b-902c-4aab-9e5d-403ce443f08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17cc6213-efa5-42ef-8d91-f8bc71cf7587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value counts and percentages for column country:\n",
      "country\n",
      "Argentina    20.0\n",
      "Canada       20.0\n",
      "Estonia      20.0\n",
      "Japan        20.0\n",
      "Spain        20.0\n",
      "Name: country, dtype: float64\n",
      "Unique value counts and percentages for column store:\n",
      "store\n",
      "Kagglazon       33.333333\n",
      "Kaggle Learn    33.333333\n",
      "Kaggle Store    33.333333\n",
      "Name: store, dtype: float64\n",
      "Unique value counts and percentages for column product:\n",
      "product\n",
      "Using LLMs to Improve Your Coding                 20.0\n",
      "Using LLMs to Train More LLMs                     20.0\n",
      "Using LLMs to Win Friends and Influence People    20.0\n",
      "Using LLMs to Win More Kaggle Competitions        20.0\n",
      "Using LLMs to Write Better                        20.0\n",
      "Name: product, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cols= ['country', 'store', 'product' ]\n",
    "for col in cols:\n",
    "  df_grouped = test.groupby(col)[col].count()\n",
    "  df_grouped = df_grouped / test[col].count() * 100\n",
    "  print(f\"Unique value counts and percentages for column {col}:\")\n",
    "  print(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eafd7c33-d628-4284-9b6f-dbc8d48b7690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44713c93-eb9a-4489-a5b9-6f4a36ce4e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolumna: country\n",
      "  Warto≈õƒá zakodowana: 0 -> Warto≈õƒá poczƒÖtkowa: Argentina\n",
      "  Warto≈õƒá zakodowana: 1 -> Warto≈õƒá poczƒÖtkowa: Canada\n",
      "  Warto≈õƒá zakodowana: 2 -> Warto≈õƒá poczƒÖtkowa: Estonia\n",
      "  Warto≈õƒá zakodowana: 3 -> Warto≈õƒá poczƒÖtkowa: Japan\n",
      "  Warto≈õƒá zakodowana: 4 -> Warto≈õƒá poczƒÖtkowa: Spain\n",
      "Kolumna: store\n",
      "  Warto≈õƒá zakodowana: 0 -> Warto≈õƒá poczƒÖtkowa: Kagglazon\n",
      "  Warto≈õƒá zakodowana: 1 -> Warto≈õƒá poczƒÖtkowa: Kaggle Learn\n",
      "  Warto≈õƒá zakodowana: 2 -> Warto≈õƒá poczƒÖtkowa: Kaggle Store\n",
      "Kolumna: product\n",
      "  Warto≈õƒá zakodowana: 0 -> Warto≈õƒá poczƒÖtkowa: Using LLMs to Improve Your Coding\n",
      "  Warto≈õƒá zakodowana: 1 -> Warto≈õƒá poczƒÖtkowa: Using LLMs to Train More LLMs\n",
      "  Warto≈õƒá zakodowana: 2 -> Warto≈õƒá poczƒÖtkowa: Using LLMs to Win Friends and Influence People\n",
      "  Warto≈õƒá zakodowana: 3 -> Warto≈õƒá poczƒÖtkowa: Using LLMs to Win More Kaggle Competitions\n",
      "  Warto≈õƒá zakodowana: 4 -> Warto≈õƒá poczƒÖtkowa: Using LLMs to Write Better\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "Enc_col = ['country', 'store', 'product' ]\n",
    "\n",
    "# Fit the encoder and create the mapping for each column separately\n",
    "categories = {}\n",
    "for col in Enc_col:\n",
    "    for df in [train, test]:\n",
    "        df[col + '_Enc'] = enc.fit_transform(df[col].values.reshape(-1, 1))\n",
    "    categories[col] = enc.categories_[0]  # Store categories for the current column\n",
    "\n",
    "# Print the mapping\n",
    "for col in Enc_col:\n",
    "    print(f\"Kolumna: {col}\")\n",
    "    for i, category in enumerate(categories[col]):\n",
    "        print(f\"  Warto≈õƒá zakodowana: {i} -> Warto≈õƒá poczƒÖtkowa: {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be7de321-f677-425b-93e3-f6766a83e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['id','country', 'store', 'product' ]\n",
    "for df in [train, test]:\n",
    "     df.drop(columns=categorical_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2285d0-b382-4352-b10b-d9387a1ec99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>country_Enc</th>\n",
       "      <th>store_Enc</th>\n",
       "      <th>product_Enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136945</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>700</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136946</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>752</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136947</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>111</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136948</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>641</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136949</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>539</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  num_sold  country_Enc  store_Enc  product_Enc\n",
       "136945 2021-12-31       700          4.0        0.0          0.0\n",
       "136946 2021-12-31       752          4.0        0.0          1.0\n",
       "136947 2021-12-31       111          4.0        0.0          2.0\n",
       "136948 2021-12-31       641          4.0        0.0          3.0\n",
       "136949 2021-12-31       539          4.0        0.0          4.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9218662e-a626-40b4-b8eb-605148b39390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country_Enc</th>\n",
       "      <th>store_Enc</th>\n",
       "      <th>product_Enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  country_Enc  store_Enc  product_Enc\n",
       "0 2022-01-01          0.0        1.0          0.0\n",
       "1 2022-01-01          0.0        1.0          1.0\n",
       "2 2022-01-01          0.0        1.0          2.0\n",
       "3 2022-01-01          0.0        1.0          3.0\n",
       "4 2022-01-01          0.0        1.0          4.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90bf1e53-2fe4-43aa-a527-1098557bbb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136950 entries, 0 to 136949\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   date         136950 non-null  datetime64[ns]\n",
      " 1   num_sold     136950 non-null  int64         \n",
      " 2   country_Enc  136950 non-null  float64       \n",
      " 3   store_Enc    136950 non-null  float64       \n",
      " 4   product_Enc  136950 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1)\n",
      "memory usage: 5.2 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41d44ff8-bf61-41b1-a2da-1145ef7df514",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['country_Enc', 'store_Enc', 'product_Enc']] = train[['country_Enc', 'store_Enc', 'product_Enc']].astype(np.int8)\n",
    "test[['country_Enc', 'store_Enc', 'product_Enc']] = test[['country_Enc', 'store_Enc', 'product_Enc']].astype(np.int8)\n",
    "train['num_sold'] = train['num_sold'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccc82574-4a32-4323-9c49-6fe0fdc66b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136950 entries, 0 to 136949\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   date         136950 non-null  datetime64[ns]\n",
      " 1   num_sold     136950 non-null  int16         \n",
      " 2   country_Enc  136950 non-null  int8          \n",
      " 3   store_Enc    136950 non-null  int8          \n",
      " 4   product_Enc  136950 non-null  int8          \n",
      "dtypes: datetime64[ns](1), int16(1), int8(3)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "599228c5-95b3-4654-a04f-44ae529c6de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27375 entries, 0 to 27374\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   date         27375 non-null  datetime64[ns]\n",
      " 1   country_Enc  27375 non-null  int8          \n",
      " 2   store_Enc    27375 non-null  int8          \n",
      " 3   product_Enc  27375 non-null  int8          \n",
      "dtypes: datetime64[ns](1), int8(3)\n",
      "memory usage: 294.2 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b66d617-7783-4022-8b53-5d54983a504a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(train['date'].isna().any()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7546bb5-010d-4e1a-a2c4-a16524d1bffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataa, targett \u001b[38;5;241m=\u001b[39m train_loader\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "dataa, targett = train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2c73b39-1605-4e01-a473-b20526db4c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "datetime64[ns]\n",
      "tensor(63.)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m test_loader  \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_dataset[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 62\u001b[0m A, B \u001b[38;5;241m=\u001b[39mtrain_loader\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam  # Import Adam optimizer\n",
    "\n",
    "\n",
    "# Check data types\n",
    "print(train['date'].dtype)\n",
    "print(test['date'].dtype)\n",
    "\n",
    "# Handle missing values (optional)\n",
    "if train['date'].isna().any():\n",
    "   print(\"There are missing values in 'date' column of train data\")\n",
    "    # Choose a handling method (e.g., remove rows, impute values)\n",
    "\n",
    "if test['date'].isna().any():\n",
    "   print(\"There are missing values in 'date' column of test data\")\n",
    "    # Choose a handling method for test data as well\n",
    "\n",
    "train['year'] = pd.to_datetime(train['date']).dt.year\n",
    "train['month'] = pd.to_datetime(train['date']).dt.month\n",
    "train['day'] = pd.to_datetime(train['date']).dt.day\n",
    "test['year'] = pd.to_datetime(test['date']).dt.year\n",
    "test['month'] = pd.to_datetime(test['date']).dt.month\n",
    "test['day'] = pd.to_datetime(test['date']).dt.day\n",
    "\n",
    "    # Separate features and target (excluding date features)\n",
    "\n",
    "def prepare_data_no_look_back(df, categorical_cols, is_training=True):\n",
    "  # Separate features based on training/prediction mode\n",
    "  if is_training:\n",
    "    features = df[categorical_cols]\n",
    "    target = df['num_sold']\n",
    "  else:\n",
    "    features = df[categorical_cols]  # No target for prediction\n",
    "\n",
    "  X_tensor = torch.from_numpy(features.to_numpy(dtype=float)).float()\n",
    "\n",
    "  # Create tensors only for training\n",
    "  if is_training:\n",
    "    y_tensor = torch.from_numpy(target.to_numpy(dtype=float)).float()  # Assuming num_sold is float\n",
    "    dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "    return dataset\n",
    "  else:\n",
    "    # Return only features for prediction\n",
    "    return X_tensor\n",
    "    \n",
    "# Assuming 'train' is your training dataframe\n",
    "categorical_cols = ['year', 'month', 'day', \"country_Enc\", \"store_Enc\", \"product_Enc\"]\n",
    "\n",
    "# Prepare training data\n",
    "train_dataset   = prepare_data_no_look_back(train.copy(), categorical_cols)  # Avoid modifying original dataframe\n",
    "test_dataset    = prepare_data_no_look_back(test.copy(), categorical_cols, is_training=False)\n",
    "\n",
    "# Create a DataLoader for batch training\n",
    "batch_size = 64  # Adjust batch size as needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(train_dataset[0][1])\n",
    "A, B =train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5433e1c5-7982-4f18-9f8b-e3e7c2fe00e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[0;32m     39\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(prediction, target)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[25], line 11\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Use last hidden state for prediction\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Pass through final linear layer\u001b[39;00m\n\u001b[0;32m     13\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "    super(LSTMModel, self).__init__()\n",
    "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "    self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Pass through LSTM layers\n",
    "    x, _ = self.lstm(x)\n",
    "    # Use last hidden state for prediction\n",
    "    x = x[:, -1, :]\n",
    "    # Pass through final linear layer\n",
    "    out = self.fc(x)\n",
    "    return out\n",
    "\n",
    "# Hyperparameters (adjust as needed)\n",
    "input_size = len(categorical_cols)  # Number of features\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 1  # Assuming predicting single value (num_sold)\n",
    "\n",
    "# Create model and optimizer\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()  # Mean Squared Error loss for regression\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    # Access features and target explicitly\n",
    "    features = data\n",
    "    targets = target\n",
    "    # Clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    prediction = model(data)\n",
    "    # Calculate loss\n",
    "    loss = loss_fn(prediction, target)\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print training progress (optional)\n",
    "    if (i+1) % 100 == 0:\n",
    "      print(f'Epoch: {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# # Prediction on test data (example)\n",
    "# def predict(model, data_loader):\n",
    "#   predictions = []\n",
    "#   with torch.no_grad():\n",
    "#     for data in data_loader:\n",
    "#       prediction = model(data)\n",
    "#       predictions.extend(prediction.squeeze(0).numpy())  # Remove batch dimension\n",
    "#   return predictions\n",
    "\n",
    "test_predictions = predict(model, test_loader)\n",
    "print(f'Example prediction: {test_predictions[0]}')\n",
    "\n",
    "#Kurwa maƒá no ju≈º nie wiem o co tu chodzi aaaaaaaaaaaaaaaaaaaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e52b3-9203-49de-b690-5e51d9ff1018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcacc67-4d89-484e-ac98-ce72228a7ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
