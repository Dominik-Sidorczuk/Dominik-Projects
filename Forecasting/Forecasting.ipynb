{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b018a-b49b-4033-8b60-2465aa3f3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta,date\n",
    "\n",
    "# \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_palette('icefire_r', 2)\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "#Przetwarzanie\n",
    "\n",
    "# Baza danych gównych do nauki modelu\n",
    "train = pd.read_csv(\"train.csv\") \n",
    "# Baza danych Titanica do sprawdzenia modelu\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587595f-4bf6-431e-94bb-d61499e6f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ab997-3237-4e0d-909a-db173f2c1d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ddccef-88c9-40e4-ba9c-58e5660b7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.isnull(train).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2069e7-38bd-4dcf-a7de-54225a9805f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.isnull(test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b9301-440d-42fb-80b9-47f45aa45db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= ['country', 'store', 'product' ]\n",
    "for col in cols:\n",
    "  df_grouped = train.groupby(col)[col].count()\n",
    "  df_grouped = df_grouped / train[col].count() * 100\n",
    "  print(f\"Unique value counts and percentages for column {col}:\")\n",
    "  print(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cc6213-efa5-42ef-8d91-f8bc71cf7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= ['country', 'store', 'product' ]\n",
    "for col in cols:\n",
    "  df_grouped = test.groupby(col)[col].count()\n",
    "  df_grouped = df_grouped / test[col].count() * 100\n",
    "  print(f\"Unique value counts and percentages for column {col}:\")\n",
    "  print(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd7c33-d628-4284-9b6f-dbc8d48b7690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44713c93-eb9a-4489-a5b9-6f4a36ce4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "Enc_col = ['country', 'store', 'product' ]\n",
    "\n",
    "# Fit the encoder and create the mapping for each column separately\n",
    "categories = {}\n",
    "for col in Enc_col:\n",
    "    for df in [train, test]:\n",
    "        df[col + '_Enc'] = enc.fit_transform(df[col].values.reshape(-1, 1))\n",
    "    categories[col] = enc.categories_[0]  # Store categories for the current column\n",
    "\n",
    "# Print the mapping\n",
    "for col in Enc_col:\n",
    "    print(f\"Kolumna: {col}\")\n",
    "    for i, category in enumerate(categories[col]):\n",
    "        print(f\"  Wartość zakodowana: {i} -> Wartość początkowa: {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7de321-f677-425b-93e3-f6766a83e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['id','country', 'store', 'product' ]\n",
    "for df in [train, test]:\n",
    "     df.drop(columns=categorical_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2285d0-b382-4352-b10b-d9387a1ec99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218662e-a626-40b4-b8eb-605148b39390",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf1e53-2fe4-43aa-a527-1098557bbb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d44ff8-bf61-41b1-a2da-1145ef7df514",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['country_Enc', 'store_Enc', 'product_Enc']] = train[['country_Enc', 'store_Enc', 'product_Enc']].astype(np.int8)\n",
    "test[['country_Enc', 'store_Enc', 'product_Enc']] = test[['country_Enc', 'store_Enc', 'product_Enc']].astype(np.int8)\n",
    "train['num_sold'] = train['num_sold'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc82574-4a32-4323-9c49-6fe0fdc66b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599228c5-95b3-4654-a04f-44ae529c6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b66d617-7783-4022-8b53-5d54983a504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['date'].isna().any()) \n",
    "train = train.set_index('date')\n",
    "test = test.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce5293-67e1-4209-85fa-29131e9c466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam  # Import Adam optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c73b39-1605-4e01-a473-b20526db4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"country_Enc\", \"store_Enc\", \"product_Enc\"]\n",
    "target   = 'num_sold'\n",
    "\n",
    "# Przygotuj dane dla modelu\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_test = test[features]\n",
    "\n",
    "# Konwertuj dane na tensory PyTorch\n",
    "X_tensor_train = torch.from_numpy(X_train.to_numpy()).float()\n",
    "y_tensor_train = torch.from_numpy(y_train.to_numpy()).float()\n",
    "\n",
    "# Konwertuj dane na tensory PyTorch\n",
    "X_tensor_test = torch.from_numpy(X_test.to_numpy()).float()\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, X_tensor, y_tensor):\n",
    "    if y_tensor is not None:\n",
    "      # Handle missing labels (e.g., remove data points or assign a specific value)\n",
    "      # Option 1: Remove data points with missing labels\n",
    "      # filtered_indices = [i for i, label in enumerate(y_tensor) if label is not None]\n",
    "      # self.X_tensor = X_tensor[filtered_indices]\n",
    "      # self.y_tensor = y_tensor[filtered_indices]\n",
    "\n",
    "      # Option 2: Assign a specific value for missing labels\n",
    "      self.y_tensor = [label if label is not None else -1 for label in y_tensor]  # Replace with your chosen value\n",
    "    self.X_tensor = X_tensor\n",
    "    self.y_tensor = y_tensor\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    X = self.X_tensor[idx]\n",
    "    y = self.y_tensor[idx]  # Assuming labels are handled in __init__\n",
    "    return X, y\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X_tensor)\n",
    "\n",
    "train_dataset = MyDataset(X_tensor_train, y_tensor_train)\n",
    "test_dataset = MyDataset(X_tensor_test, None) \n",
    "\n",
    "# Create a DataLoader for batch training\n",
    "batch_size = 512  # Adjust batch size as needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75545c02-479d-4878-9051-f2f360cddf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=2, dropout=0.2)  # Add dropout for regularization\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through LSTM layers\n",
    "        x, (hidden, cell) = self.lstm(x)\n",
    "        # Use the output from the last hidden layer\n",
    "        x = hidden[-1]  # Consider using both hidden and cell for complex tasks (optional)\n",
    "        # Apply linear layer for prediction\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Hyperparameters (adjust as needed)\n",
    "input_dim = len(features)  # Number of features\n",
    "hidden_dim = 64\n",
    "num_layers = 1\n",
    "output_dim = 1  # Assuming predicting single value (num_sold)\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Set learning rate\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "print_every = 100\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()  # Set model to training mode\n",
    "  for batch_x, batch_y in train_loader:\n",
    "    #print(f\"Batch_x shape: {batch_x.shape}\")  # Print shapes for debugging\n",
    "    #print(f\"Batch_y shape: {batch_y.shape}\")  # Print shapes for debugging\n",
    "    optimizer.zero_grad()\n",
    "    for x, y in zip(batch_x, batch_y):  # Iterate over elements in each batch\n",
    "      x = x.unsqueeze(0)\n",
    "      y_pred = model(x)  # Pass each feature (x) through the model\n",
    "      loss = criterion(y_pred, y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    if (i + 1) % print_every == 0:\n",
    "      print(f'Epoch: {epoch+1}, Batch: {i+1}, Loss: {loss.item()}')\n",
    "    # # Optional: Validation loop\n",
    "    # with torch.no_grad():\n",
    "    #     val_loss = 0.0\n",
    "    #     for batch_x, batch_y in val_loader:\n",
    "    #         y_pred = model(batch_x)\n",
    "    #         val_loss += criterion(y_pred, batch_y).item()\n",
    "    #     val_loss /= len(val_loader)\n",
    "    #     print('Validation Loss: {:.4f}'.format(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a54bf6-ced9-4e68-b94a-48b91f234030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a83db-61a9-4c07-b0cb-2b6800feafa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfd210-a45b-4a76-89e1-efc2bf216885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5433e1c5-7982-4f18-9f8b-e3e7c2fe00e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e52b3-9203-49de-b690-5e51d9ff1018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcacc67-4d89-484e-ac98-ce72228a7ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
