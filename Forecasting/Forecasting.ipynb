{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b747e57-6370-4fb0-ab08-7cbe4de28233",
   "metadata": {},
   "source": [
    "JUŻ WIEM  \n",
    "Dwa podjeścia pierwsze prostsze Lepsze dlza SARMIX. Przekształcenie data frama jednowwymarowo tworząc 32 unikatowe kolumny i w każdą wpisać wartośc sprzedaży. każday oddzielny rząd ma inny dzień nie da się jedk tego zastosować dla Pytorcha  \n",
    "Drugie wielowymiarowe, również 32 kolumny, ale nie wpisuje wartości num_sold a 1 wtedy gdy dana kombinacja występuje, dzięki czemu mam odzielną kolumnę z targetem dla Pytorcha najelepsze podjeście. Łatwiejsze w ponieważ nie będzie trzeba póżniej dekodować danych względem ID do przesłania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528b018a-b49b-4033-8b60-2465aa3f3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta,date\n",
    "from numba import jit\n",
    "\n",
    "# \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_palette('icefire_r', 2)\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from plotly.io import show\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "#Przetwarzanie\n",
    "\n",
    "# Baza danych gównych do nauki modelu\n",
    "train = pd.read_csv(\"train.csv\") \n",
    "# Baza danych Titanica do sprawdzenia modelu\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4bbeb0-10cb-4916-8750-276043007749",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "# train = train.set_index('date') \n",
    "# test = test.set_index('date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44f38701-989d-4a0b-93ca-4b7cc7c9556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id        date    country         store  \\\n",
       "0    0  2017-01-01  Argentina  Kaggle Learn   \n",
       "1    1  2017-01-01  Argentina  Kaggle Learn   \n",
       "2    2  2017-01-01  Argentina  Kaggle Learn   \n",
       "3    3  2017-01-01  Argentina  Kaggle Learn   \n",
       "4    4  2017-01-01  Argentina  Kaggle Learn   \n",
       "5    5  2017-01-01  Argentina  Kaggle Store   \n",
       "6    6  2017-01-01  Argentina  Kaggle Store   \n",
       "7    7  2017-01-01  Argentina  Kaggle Store   \n",
       "8    8  2017-01-01  Argentina  Kaggle Store   \n",
       "9    9  2017-01-01  Argentina  Kaggle Store   \n",
       "10  10  2017-01-01  Argentina     Kagglazon   \n",
       "11  11  2017-01-01  Argentina     Kagglazon   \n",
       "12  12  2017-01-01  Argentina     Kagglazon   \n",
       "13  13  2017-01-01  Argentina     Kagglazon   \n",
       "14  14  2017-01-01  Argentina     Kagglazon   \n",
       "15  15  2017-01-01     Canada  Kaggle Learn   \n",
       "16  16  2017-01-01     Canada  Kaggle Learn   \n",
       "17  17  2017-01-01     Canada  Kaggle Learn   \n",
       "18  18  2017-01-01     Canada  Kaggle Learn   \n",
       "19  19  2017-01-01     Canada  Kaggle Learn   \n",
       "20  20  2017-01-01     Canada  Kaggle Store   \n",
       "21  21  2017-01-01     Canada  Kaggle Store   \n",
       "22  22  2017-01-01     Canada  Kaggle Store   \n",
       "23  23  2017-01-01     Canada  Kaggle Store   \n",
       "24  24  2017-01-01     Canada  Kaggle Store   \n",
       "25  25  2017-01-01     Canada     Kagglazon   \n",
       "26  26  2017-01-01     Canada     Kagglazon   \n",
       "27  27  2017-01-01     Canada     Kagglazon   \n",
       "28  28  2017-01-01     Canada     Kagglazon   \n",
       "29  29  2017-01-01     Canada     Kagglazon   \n",
       "30  30  2017-01-01    Estonia  Kaggle Learn   \n",
       "31  31  2017-01-01    Estonia  Kaggle Learn   \n",
       "32  32  2017-01-01    Estonia  Kaggle Learn   \n",
       "33  33  2017-01-01    Estonia  Kaggle Learn   \n",
       "34  34  2017-01-01    Estonia  Kaggle Learn   \n",
       "\n",
       "                                           product  num_sold  \n",
       "0                Using LLMs to Improve Your Coding        63  \n",
       "1                    Using LLMs to Train More LLMs        66  \n",
       "2   Using LLMs to Win Friends and Influence People         9  \n",
       "3       Using LLMs to Win More Kaggle Competitions        59  \n",
       "4                       Using LLMs to Write Better        49  \n",
       "5                Using LLMs to Improve Your Coding        88  \n",
       "6                    Using LLMs to Train More LLMs        98  \n",
       "7   Using LLMs to Win Friends and Influence People        14  \n",
       "8       Using LLMs to Win More Kaggle Competitions        83  \n",
       "9                       Using LLMs to Write Better        69  \n",
       "10               Using LLMs to Improve Your Coding       340  \n",
       "11                   Using LLMs to Train More LLMs       371  \n",
       "12  Using LLMs to Win Friends and Influence People        53  \n",
       "13      Using LLMs to Win More Kaggle Competitions       364  \n",
       "14                      Using LLMs to Write Better       285  \n",
       "15               Using LLMs to Improve Your Coding       202  \n",
       "16                   Using LLMs to Train More LLMs       199  \n",
       "17  Using LLMs to Win Friends and Influence People        31  \n",
       "18      Using LLMs to Win More Kaggle Competitions       202  \n",
       "19                      Using LLMs to Write Better       138  \n",
       "20               Using LLMs to Improve Your Coding       274  \n",
       "21                   Using LLMs to Train More LLMs       288  \n",
       "22  Using LLMs to Win Friends and Influence People        47  \n",
       "23      Using LLMs to Win More Kaggle Competitions       268  \n",
       "24                      Using LLMs to Write Better       249  \n",
       "25               Using LLMs to Improve Your Coding      1041  \n",
       "26                   Using LLMs to Train More LLMs      1101  \n",
       "27  Using LLMs to Win Friends and Influence People       166  \n",
       "28      Using LLMs to Win More Kaggle Competitions      1062  \n",
       "29                      Using LLMs to Write Better       866  \n",
       "30               Using LLMs to Improve Your Coding        92  \n",
       "31                   Using LLMs to Train More LLMs        89  \n",
       "32  Using LLMs to Win Friends and Influence People        14  \n",
       "33      Using LLMs to Win More Kaggle Competitions        81  \n",
       "34                      Using LLMs to Write Better        70  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9a4baa0-313a-4f37-b44d-8ae21cff1f6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of names must match number of levels in MultiIndex.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m multi_index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mMultiIndex\u001b[38;5;241m.\u001b[39mfrom_frame(train,names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mset_index(multi_index, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:754\u001b[0m, in \u001b[0;36mMultiIndex.from_frame\u001b[1;34m(cls, df, sortorder, names)\u001b[0m\n\u001b[0;32m    752\u001b[0m column_names, columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mdf\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    753\u001b[0m names \u001b[38;5;241m=\u001b[39m column_names \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m names\n\u001b[1;32m--> 754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_arrays(columns, sortorder\u001b[38;5;241m=\u001b[39msortorder, names\u001b[38;5;241m=\u001b[39mnames)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:537\u001b[0m, in \u001b[0;36mMultiIndex.from_arrays\u001b[1;34m(cls, arrays, sortorder, names)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m    535\u001b[0m     names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(arr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 537\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    538\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    539\u001b[0m     codes\u001b[38;5;241m=\u001b[39mcodes,\n\u001b[0;32m    540\u001b[0m     sortorder\u001b[38;5;241m=\u001b[39msortorder,\n\u001b[0;32m    541\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    542\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    543\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:356\u001b[0m, in \u001b[0;36mMultiIndex.__new__\u001b[1;34m(cls, levels, codes, sortorder, names, dtype, copy, name, verify_integrity)\u001b[0m\n\u001b[0;32m    353\u001b[0m result\u001b[38;5;241m.\u001b[39m_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(levels)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;66;03m# handles name validation\u001b[39;00m\n\u001b[1;32m--> 356\u001b[0m     result\u001b[38;5;241m.\u001b[39m_set_names(names)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sortorder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     result\u001b[38;5;241m.\u001b[39msortorder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(sortorder)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:1609\u001b[0m, in \u001b[0;36mMultiIndex._set_names\u001b[1;34m(self, names, level, validate)\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of names must match length of level.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels:\n\u001b[1;32m-> 1609\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1610\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of names must match number of levels in MultiIndex.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1611\u001b[0m         )\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1614\u001b[0m     level \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels)\n",
      "\u001b[1;31mValueError\u001b[0m: Length of names must match number of levels in MultiIndex."
     ]
    }
   ],
   "source": [
    "multi_index = pd.MultiIndex.from_frame(train[['date', 'id']], names=['date', 'id'])  # Select 'date' and 'id' columns explicitly\n",
    "df.set_index(multi_index, inplace=True)df.set_index(multi_index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db7ee6-13d0-407d-a2f2-c0afb08da341",
   "metadata": {},
   "outputs": [],
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ddccef-88c9-40e4-ba9c-58e5660b7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.isnull(train).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2069e7-38bd-4dcf-a7de-54225a9805f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.isnull(test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b9301-440d-42fb-80b9-47f45aa45db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols= ['country', 'store', 'product' ]\n",
    "# for col in cols:\n",
    "#   df_grouped = train.groupby(col)[col].count()\n",
    "#   df_grouped = df_grouped / train[col].count() * 100\n",
    "#   print(f\"Unique value counts and percentages for column {col}:\")\n",
    "#   print(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cc6213-efa5-42ef-8d91-f8bc71cf7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols= ['country', 'store', 'product' ]\n",
    "# for col in cols:\n",
    "#   df_grouped = test.groupby(col)[col].count()\n",
    "#   df_grouped = df_grouped / test[col].count() * 100\n",
    "#   print(f\"Unique value counts and percentages for column {col}:\")\n",
    "#   print(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba216df9-ab59-4920-bcff-f5b527c6b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc41d18-b536-4e3a-b552-f2cb45436a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd7c33-d628-4284-9b6f-dbc8d48b7690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "\n",
    "train['year'] = pd.to_datetime(train['date']).dt.year\n",
    "train['month'] = pd.to_datetime(train['date']).dt.month\n",
    "train['day'] = pd.to_datetime(train['date']).dt.day\n",
    "test['year'] = pd.to_datetime(test['date']).dt.year\n",
    "test['month'] = pd.to_datetime(test['date']).dt.month\n",
    "test['day'] = pd.to_datetime(test['date']).dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8fb36-c0c2-4ef5-818d-a7f9a426b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index('date') \n",
    "test = test.set_index('date')\n",
    "\n",
    "#train.index = train.index.to_period(freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445bd005-dfcd-4ab1-b574-c2e682aaf00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8198c121-5ce3-4c84-9548-0f7246a18ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = sns.lineplot(train, x=train.index.to_timestamp() , y='num_sold', hue=train['country']=='Spain')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44713c93-eb9a-4489-a5b9-6f4a36ce4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "Enc_col = ['country', 'store', 'product' ]\n",
    "\n",
    "# Fit the encoder and create the mapping for each column separately\n",
    "categories = {}\n",
    "for col in Enc_col:\n",
    "    for df in [train, test]:\n",
    "        df[col + '_Enc'] = enc.fit_transform(df[col].values.reshape(-1, 1))\n",
    "    categories[col] = enc.categories_[0]  # Store categories for the current column\n",
    "\n",
    "# Print the mapping\n",
    "for col in Enc_col:\n",
    "    print(f\"Kolumna: {col}\")\n",
    "    for i, category in enumerate(categories[col]):\n",
    "        print(f\"  Wartość zakodowana: {i} -> Wartość początkowa: {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d44ff8-bf61-41b1-a2da-1145ef7df514",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['country_Enc', 'store_Enc', 'product_Enc']] = train[['country_Enc', 'store_Enc', 'product_Enc']].astype(np.int8)\n",
    "test[['country_Enc', 'store_Enc', 'product_Enc']] = test[['country_Enc', 'store_Enc', 'product_Enc']].astype(np.int8)\n",
    "train['num_sold'] = train['num_sold'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7de321-f677-425b-93e3-f6766a83e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['id','country', 'store', 'product' ]\n",
    "for df in [train, test]:\n",
    "     df.drop(columns=categorical_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf1e53-2fe4-43aa-a527-1098557bbb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed9e2f-b9de-4ca5-9cd7-a543c2e5a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1575a0e9-8181-43ee-a85c-1846f49e5394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train.head()\n",
    "scaler= MinMaxScaler()\n",
    "# -------------------------------------------------------------\n",
    "train_num_sol_reshaped = train['num_sold'].values.reshape(-1, 1)  # Reshape to 2D\n",
    "scaler.fit(train_num_sol_reshaped)\n",
    "train['num_sold_scaled'] = scaler.transform(train_num_sol_reshaped)\n",
    "#----------------------------------------------------------------\n",
    "train.drop('num_sold', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad333b4-2195-4e91-b236-e2bc6b7361ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Spain = train[train['country_Enc'] == 4]\n",
    "train_Spain, val_Spain = train_test_split(Spain, test_size=0.25, shuffle=False)\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig = go.Figure(layout=dict(xaxis_title=\"Date\", yaxis_title=\"Sales\"))\n",
    "\n",
    "# Plot train_Spain data in first subplot\n",
    "trace1 = go.Scatter(\n",
    "    x=train_Spain.index(),\n",
    "    y=train_Spain['num_sold_scaled'],\n",
    "    name=\"Train\",\n",
    "    mode=\"markers\",\n",
    "    marker=dict(color=\"blue\", size=2),\n",
    ")\n",
    "\n",
    "# Plot val_Spain data in second subplot\n",
    "trace2 = go.Scatter(\n",
    "    x=val_Spain.index(),\n",
    "    y=val_Spain['num_sold_scaled'],\n",
    "    name=\"Validation\",\n",
    "    mode=\"markers\",\n",
    "    marker=dict(color=\"red\", size=2)\n",
    ")\n",
    "# trace3 = go.Scatter(x=Spain.index.to_timestamp(), y=Spain['num_sold_scaled'], name=\"spline\",\n",
    "#                     text=[\"tweak line smoothness<br>with 'smoothing' in line object\"],\n",
    "#                     hoverinfo='text+name',\n",
    "#                     line_shape='spline', \n",
    "#                     line=dict(smoothing=1.3)  # Adjust this value to control smoothness\n",
    "# )\n",
    "\n",
    "# Add traces to the figure\n",
    "fig.add_trace(trace1)\n",
    "fig.add_trace(trace2)\n",
    "# fig.add_trace(trace3)\n",
    "\n",
    "# Display the chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560fdec3-48c0-46ce-b9de-ffd65a6aa33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "from statsmodels.tsa.api import SARIMAX\n",
    "\n",
    "\n",
    "# Assuming 'train' is your DataFrame with 'num_sold_scaled' as the target variable\n",
    "det_proc = DeterministicProcess(train_Spain.index, constant=False, fourier=3 )\n",
    "det_proc.in_sample()\n",
    "\n",
    "train_with_exo = pd.concat([train_Spain['num_sold_scaled'], det_proc.in_sample()], axis=1)\n",
    "model = SARIMAX(train_with_exo['num_sold_scaled'],\n",
    "                     order=(1, 1, 1),  # Adjust order parameters as needed\n",
    "                     seasonal_order=(1, 1, 1, 12),  # Adjust seasonal order as needed\n",
    "                     exog=train_with_exo[['sin(1,7)', 'cos(1,7)',\t'sin(2,7)',\t'cos(2,7)',\t'sin(3,7)',\t'cos(3,7)']])\n",
    "\n",
    "SARIMAX_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e3bc55-e73a-44f8-93eb-6e44397d0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SARIMAX_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac9f23-dd15-4509-a03b-3638e0cbf175",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Spain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77028987-c545-465b-a645-0cb9fa3ca519",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = SARIMAX_fit.forecast(len(val_Spain), exog=det_proc.out_of_sample(len(val_Spain)))\n",
    "forecast.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72667958-44b4-465d-8abc-7d3a007e684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce5293-67e1-4209-85fa-29131e9c466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam  # Import Adam optimizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "torch.set_num_threads(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c73b39-1605-4e01-a473-b20526db4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['year', 'month', 'day', \"country_Enc\", \"store_Enc\", \"product_Enc\"]\n",
    "target   = 'num_sold_scaled'\n",
    "\n",
    "# Przygotuj dane dla modelu\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_test = test[features]\n",
    "\n",
    "# Konwertuj dane na tensory PyTorch\n",
    "X_tensor_train = torch.from_numpy(X_train.to_numpy()).float()\n",
    "y_tensor_train = torch.from_numpy(y_train.to_numpy()).float().reshape(-1, 1)\n",
    "\n",
    "# Konwertuj dane na tensory PyTorch\n",
    "X_tensor_test = torch.from_numpy(X_test.to_numpy()).float()\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, X_tensor, y_tensor):\n",
    "    if y_tensor is not None:\n",
    "      # Handle missing labels (e.g., assign a specific value)\n",
    "      self.y_tensor = [label if label is not None else -1 for label in y_tensor]\n",
    "    self.X_tensor = X_tensor\n",
    "    self.y_tensor = y_tensor\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    X = self.X_tensor[idx]\n",
    "    y = self.y_tensor[idx]\n",
    "    return X, y\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X_tensor)\n",
    "\n",
    "train_dataset = MyDataset(X_tensor_train, y_tensor_train)\n",
    "test_dataset = MyDataset(X_tensor_test, None) \n",
    "\n",
    "train_size = int(0.20 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create a DataLoader for batch training\n",
    "batch_size = 2048 # Adjust batch size as needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75545c02-479d-4878-9051-f2f360cddf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "    super(LSTMModel, self).__init__()\n",
    "    self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, dropout=0.2)  # Add dropout for regularization\n",
    "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    self.silu = nn.SiLU()  # Add SiLU activation layer\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Pass the input through LSTM layers\n",
    "    x, (hidden, cell) = self.lstm(x)\n",
    "    # Use the output from the last hidden layer\n",
    "    x = hidden[-1]\n",
    "    # Apply SiLU activation before linear layer\n",
    "    x = self.silu(x)\n",
    "    # Apply linear layer for prediction\n",
    "    x = self.fc(x)\n",
    "    return x\n",
    "\n",
    "# Hyperparameters (adjust as needed)\n",
    "input_dim = len(features)  # Number of features\n",
    "hidden_dim =256\n",
    "num_layers = 4\n",
    "output_dim = 1  # Assuming predicting single value (num_sold)\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim).float()\n",
    "criterion = nn.HuberLoss()\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=0.005)  # Set learning rate\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 36\n",
    "best_loss = float('inf')\n",
    "print(model)\n",
    "loss_history = []  # Initialize a list to store loss values\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    pbar = tqdm(train_loader)  # Wrap train_loader with tqdm\n",
    "    for batch_x, batch_y in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        for x, y in zip(batch_x, batch_y):\n",
    "            x = x.unsqueeze(0)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.set_description(f\"Epoch {epoch+1}/{num_epochs} Loss: {loss.item():.2f}\")\n",
    "\n",
    "        # Append loss to history\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "    # Plot loss history after each epoch\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(loss_history, label='Training Loss')\n",
    "    plt.title(f\"Training Loss (Epochs: {num_epochs})\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e363c6-1b47-4620-ba26-cb379e9bb466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
