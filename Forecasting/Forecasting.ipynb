{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3379689f-1094-4132-bcb9-21c7ee6d931b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "528b018a-b49b-4033-8b60-2465aa3f3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta,date\n",
    "\n",
    "# \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_palette('icefire_r', 2)\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "#Przetwarzanie\n",
    "\n",
    "# Baza danych g√≥wnych do nauki modelu\n",
    "train = pd.read_csv(\"train.csv\") \n",
    "# Baza danych Titanica do sprawdzenia modelu\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2587595f-4bf6-431e-94bb-d61499e6f3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date    country         store  \\\n",
       "0   0  2017-01-01  Argentina  Kaggle Learn   \n",
       "1   1  2017-01-01  Argentina  Kaggle Learn   \n",
       "2   2  2017-01-01  Argentina  Kaggle Learn   \n",
       "3   3  2017-01-01  Argentina  Kaggle Learn   \n",
       "4   4  2017-01-01  Argentina  Kaggle Learn   \n",
       "\n",
       "                                          product  num_sold  \n",
       "0               Using LLMs to Improve Your Coding        63  \n",
       "1                   Using LLMs to Train More LLMs        66  \n",
       "2  Using LLMs to Win Friends and Influence People         9  \n",
       "3      Using LLMs to Win More Kaggle Competitions        59  \n",
       "4                      Using LLMs to Write Better        49  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "363ab997-3237-4e0d-909a-db173f2c1d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136950</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136951</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136952</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136953</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136954</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id        date    country         store  \\\n",
       "0  136950  2022-01-01  Argentina  Kaggle Learn   \n",
       "1  136951  2022-01-01  Argentina  Kaggle Learn   \n",
       "2  136952  2022-01-01  Argentina  Kaggle Learn   \n",
       "3  136953  2022-01-01  Argentina  Kaggle Learn   \n",
       "4  136954  2022-01-01  Argentina  Kaggle Learn   \n",
       "\n",
       "                                          product  \n",
       "0               Using LLMs to Improve Your Coding  \n",
       "1                   Using LLMs to Train More LLMs  \n",
       "2  Using LLMs to Win Friends and Influence People  \n",
       "3      Using LLMs to Win More Kaggle Competitions  \n",
       "4                      Using LLMs to Write Better  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ddccef-88c9-40e4-ba9c-58e5660b7435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "date        0\n",
      "country     0\n",
      "store       0\n",
      "product     0\n",
      "num_sold    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.isnull(train).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2069e7-38bd-4dcf-a7de-54225a9805f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id         0\n",
      "date       0\n",
      "country    0\n",
      "store      0\n",
      "product    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.isnull(test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16b9301-440d-42fb-80b9-47f45aa45db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value counts and percentages for column country:\n",
      "country\n",
      "Argentina    20.0\n",
      "Canada       20.0\n",
      "Estonia      20.0\n",
      "Japan        20.0\n",
      "Spain        20.0\n",
      "Name: country, dtype: float64\n",
      "Unique value counts and percentages for column store:\n",
      "store\n",
      "Kagglazon       33.333333\n",
      "Kaggle Learn    33.333333\n",
      "Kaggle Store    33.333333\n",
      "Name: store, dtype: float64\n",
      "Unique value counts and percentages for column product:\n",
      "product\n",
      "Using LLMs to Improve Your Coding                 20.0\n",
      "Using LLMs to Train More LLMs                     20.0\n",
      "Using LLMs to Win Friends and Influence People    20.0\n",
      "Using LLMs to Win More Kaggle Competitions        20.0\n",
      "Using LLMs to Write Better                        20.0\n",
      "Name: product, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cols= ['country', 'store', 'product' ]\n",
    "for col in cols:\n",
    "  df_grouped = train.groupby(col)[col].count()\n",
    "  df_grouped = df_grouped / train[col].count() * 100\n",
    "  print(f\"Unique value counts and percentages for column {col}:\")\n",
    "  print(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed2e7b-902c-4aab-9e5d-403ce443f08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17cc6213-efa5-42ef-8d91-f8bc71cf7587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value counts and percentages for column country:\n",
      "country\n",
      "Argentina    20.0\n",
      "Canada       20.0\n",
      "Estonia      20.0\n",
      "Japan        20.0\n",
      "Spain        20.0\n",
      "Name: country, dtype: float64\n",
      "Unique value counts and percentages for column store:\n",
      "store\n",
      "Kagglazon       33.333333\n",
      "Kaggle Learn    33.333333\n",
      "Kaggle Store    33.333333\n",
      "Name: store, dtype: float64\n",
      "Unique value counts and percentages for column product:\n",
      "product\n",
      "Using LLMs to Improve Your Coding                 20.0\n",
      "Using LLMs to Train More LLMs                     20.0\n",
      "Using LLMs to Win Friends and Influence People    20.0\n",
      "Using LLMs to Win More Kaggle Competitions        20.0\n",
      "Using LLMs to Write Better                        20.0\n",
      "Name: product, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cols= ['country', 'store', 'product' ]\n",
    "for col in cols:\n",
    "  df_grouped = test.groupby(col)[col].count()\n",
    "  df_grouped = df_grouped / test[col].count() * 100\n",
    "  print(f\"Unique value counts and percentages for column {col}:\")\n",
    "  print(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eafd7c33-d628-4284-9b6f-dbc8d48b7690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44713c93-eb9a-4489-a5b9-6f4a36ce4e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolumna: country\n",
      "  Warto≈õƒá zakodowana: 0 -> Warto≈õƒá poczƒÖtkowa: Argentina\n",
      "  Warto≈õƒá zakodowana: 1 -> Warto≈õƒá poczƒÖtkowa: Canada\n",
      "  Warto≈õƒá zakodowana: 2 -> Warto≈õƒá poczƒÖtkowa: Estonia\n",
      "  Warto≈õƒá zakodowana: 3 -> Warto≈õƒá poczƒÖtkowa: Japan\n",
      "  Warto≈õƒá zakodowana: 4 -> Warto≈õƒá poczƒÖtkowa: Spain\n",
      "Kolumna: store\n",
      "  Warto≈õƒá zakodowana: 0 -> Warto≈õƒá poczƒÖtkowa: Kagglazon\n",
      "  Warto≈õƒá zakodowana: 1 -> Warto≈õƒá poczƒÖtkowa: Kaggle Learn\n",
      "  Warto≈õƒá zakodowana: 2 -> Warto≈õƒá poczƒÖtkowa: Kaggle Store\n",
      "Kolumna: product\n",
      "  Warto≈õƒá zakodowana: 0 -> Warto≈õƒá poczƒÖtkowa: Using LLMs to Improve Your Coding\n",
      "  Warto≈õƒá zakodowana: 1 -> Warto≈õƒá poczƒÖtkowa: Using LLMs to Train More LLMs\n",
      "  Warto≈õƒá zakodowana: 2 -> Warto≈õƒá poczƒÖtkowa: Using LLMs to Win Friends and Influence People\n",
      "  Warto≈õƒá zakodowana: 3 -> Warto≈õƒá poczƒÖtkowa: Using LLMs to Win More Kaggle Competitions\n",
      "  Warto≈õƒá zakodowana: 4 -> Warto≈õƒá poczƒÖtkowa: Using LLMs to Write Better\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "Enc_col = ['country', 'store', 'product' ]\n",
    "\n",
    "# Fit the encoder and create the mapping for each column separately\n",
    "categories = {}\n",
    "for col in Enc_col:\n",
    "    for df in [train, test]:\n",
    "        df[col + '_Enc'] = enc.fit_transform(df[col].values.reshape(-1, 1))\n",
    "    categories[col] = enc.categories_[0]  # Store categories for the current column\n",
    "\n",
    "# Print the mapping\n",
    "for col in Enc_col:\n",
    "    print(f\"Kolumna: {col}\")\n",
    "    for i, category in enumerate(categories[col]):\n",
    "        print(f\"  Warto≈õƒá zakodowana: {i} -> Warto≈õƒá poczƒÖtkowa: {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be7de321-f677-425b-93e3-f6766a83e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['id','country', 'store', 'product' ]\n",
    "for df in [train, test]:\n",
    "     df.drop(columns=categorical_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2285d0-b382-4352-b10b-d9387a1ec99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>country_Enc</th>\n",
       "      <th>store_Enc</th>\n",
       "      <th>product_Enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136945</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>700</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136946</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>752</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136947</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>111</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136948</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>641</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136949</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>539</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  num_sold  country_Enc  store_Enc  product_Enc\n",
       "136945 2021-12-31       700          4.0        0.0          0.0\n",
       "136946 2021-12-31       752          4.0        0.0          1.0\n",
       "136947 2021-12-31       111          4.0        0.0          2.0\n",
       "136948 2021-12-31       641          4.0        0.0          3.0\n",
       "136949 2021-12-31       539          4.0        0.0          4.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9218662e-a626-40b4-b8eb-605148b39390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country_Enc</th>\n",
       "      <th>store_Enc</th>\n",
       "      <th>product_Enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  country_Enc  store_Enc  product_Enc\n",
       "0 2022-01-01          0.0        1.0          0.0\n",
       "1 2022-01-01          0.0        1.0          1.0\n",
       "2 2022-01-01          0.0        1.0          2.0\n",
       "3 2022-01-01          0.0        1.0          3.0\n",
       "4 2022-01-01          0.0        1.0          4.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b730000-ae97-4bef-a43f-c463bb845157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           datetime64[ns]\n",
       "num_sold                int64\n",
       "country_Enc           float64\n",
       "store_Enc             float64\n",
       "product_Enc           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90bf1e53-2fe4-43aa-a527-1098557bbb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136950 entries, 0 to 136949\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   date         136950 non-null  datetime64[ns]\n",
      " 1   num_sold     136950 non-null  int64         \n",
      " 2   country_Enc  136950 non-null  float64       \n",
      " 3   store_Enc    136950 non-null  float64       \n",
      " 4   product_Enc  136950 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1)\n",
      "memory usage: 5.2 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41d44ff8-bf61-41b1-a2da-1145ef7df514",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['country_Enc', 'store_Enc', 'product_Enc']] = train[['country_Enc', 'store_Enc', 'product_Enc']].astype(np.int8)\n",
    "test[['country_Enc', 'store_Enc', 'product_Enc']] = test[['country_Enc', 'store_Enc', 'product_Enc']].astype(np.int8)\n",
    "train['num_sold'] = train['num_sold'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccc82574-4a32-4323-9c49-6fe0fdc66b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136950 entries, 0 to 136949\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   date         136950 non-null  datetime64[ns]\n",
      " 1   num_sold     136950 non-null  int16         \n",
      " 2   country_Enc  136950 non-null  int8          \n",
      " 3   store_Enc    136950 non-null  int8          \n",
      " 4   product_Enc  136950 non-null  int8          \n",
      "dtypes: datetime64[ns](1), int16(1), int8(3)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "599228c5-95b3-4654-a04f-44ae529c6de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27375 entries, 0 to 27374\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   date         27375 non-null  datetime64[ns]\n",
      " 1   country_Enc  27375 non-null  int8          \n",
      " 2   store_Enc    27375 non-null  int8          \n",
      " 3   product_Enc  27375 non-null  int8          \n",
      "dtypes: datetime64[ns](1), int8(3)\n",
      "memory usage: 294.2 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b66d617-7783-4022-8b53-5d54983a504a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(train['date'].isna().any()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7485215-7a9a-4ea7-99bb-9b753a923b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import optuna\n",
    "from optuna.study import Study\n",
    "from optuna.trial import Trial\n",
    "import optuna.storages\n",
    "\n",
    "# # Definicja modelu GRU\n",
    "# class GRUNet(nn.Module):\n",
    "#   def __init__(self, input_size, hidden_size, output_size):\n",
    "#     super(GRUNet, self).__init__()\n",
    "#     self.gru = nn.GRU(input_size, hidden_size, num_layers=1)\n",
    "#     self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "#   def forward(self, x):\n",
    "#     x, _ = self.gru(x)\n",
    "#     x = x[-1]  # Wybiera ostatni stan ukryty\n",
    "#     x = self.fc(x)\n",
    "#     return x\n",
    "\n",
    "# # Funkcja ≈Çadowania danych\n",
    "# def load_data():\n",
    "#   # Za≈Çaduj dane treningowe i testowe\n",
    "#   train_data = train\n",
    "#   test_data = test\n",
    "\n",
    "#   # Konwersja typ√≥w danych\n",
    "#   train_data['date'] = pd.to_datetime(train_data['date']).dt.timestamp().astype(float)\n",
    "#   test_data['date'] = pd.to_datetime(test_data['date']).dt.timestamp().astype(float)\n",
    "\n",
    "#   # Konwersja kolumn na tensory PyTorch\n",
    "#   train_tensors = {\n",
    "#       'date': torch.from_numpy(train_data['date'].to_numpy()).float(),\n",
    "#       'num_sold': torch.from_numpy(train_data['num_sold'].to_numpy()).long(),\n",
    "#       'country_enc': torch.from_numpy(train_data['country_Enc'].to_numpy()).long(),\n",
    "#       'store_enc': torch.from_numpy(train_data['store_Enc'].to_numpy()).long(),\n",
    "#       'product_enc': torch.from_numpy(train_data['product_Enc'].to_numpy()).long(),\n",
    "#   }\n",
    "#   test_tensors = {\n",
    "#       'date': torch.from_numpy(test_data['date'].to_numpy()).float(),\n",
    "#       'country_enc': torch.from_numpy(test_data['country_Enc'].to_numpy()).long(),\n",
    "#       'store_enc': torch.from_numpy(test_data['store_Enc'].to_numpy()).long(),\n",
    "#       'product_enc': torch.from_numpy(test_data['product_Enc'].to_numpy()).long(),\n",
    "#   }\n",
    "\n",
    "#   # Utw√≥rz zbiory danych PyTorch\n",
    "#   train_dataset = torch.utils.data.Dataset(train_tensors)\n",
    "#   test_dataset = torch.utils.data.Dataset(test_tensors)\n",
    "\n",
    "#   # Zdefiniuj ≈Çadowarki danych\n",
    "#   train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "#   test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "#   return train_loader, test_loader\n",
    "\n",
    "# # Funkcja treningu\n",
    "# def train(model, optimizer, train_loader, criterion):\n",
    "#   model.train()\n",
    "#   for data, target in train_loader:\n",
    "#     optimizer.zero_grad()\n",
    "#     output = model(data)\n",
    "#     loss = criterion(output, target)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# # Funkcja walidacji\n",
    "# def validate(model, val_loader, criterion):\n",
    "#   model.eval()\n",
    "#   running_loss = 0.0\n",
    "#   for data, target in val_loader:\n",
    "#     output = model(data)\n",
    "#     loss = criterion(output, target)\n",
    "#     running_loss += loss.item()\n",
    "#   val_loss = running_loss / len(val_loader)\n",
    "#   return val_loss\n",
    "\n",
    "# # Definicja funkcji obiektywnej dla Optuny\n",
    "# def objective(trial: Trial):\n",
    "#   # Pobierz hiperparametry z Optuny\n",
    "#   input_size = trial.suggest_int('input_size', 10, 100)\n",
    "#   hidden_size = trial.suggest_int('hidden_size', 32, 256)\n",
    "#   output_size = trial.suggest_int('output_size', 1, 10)\n",
    "#   learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2)\n",
    "\n",
    "#   # Utw√≥rz model i kryterium\n",
    "#   model = GRUNet(input_size, hidden_size, output_size)\n",
    "#   criterion = nn.MSELoss()\n",
    "\n",
    "#   # Zdefiniuj optymalizator\n",
    "#   optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#   # Pobierz dane\n",
    "#   train_loader, val_loader = load_data()\n",
    "\n",
    "#   # Trenuj i waliduj model\n",
    "#   for epoch in range(10):\n",
    "#     train(model, optimizer, train_loader, criterion)\n",
    "#     val_loss = validate(model, val_loader, criterion)\n",
    "#     trial.report(val_loss, step=epoch)\n",
    "\n",
    "#   # Wybierz najlepszy model\n",
    "#   if val_loss is not None:\n",
    "#     return val_loss\n",
    "\n",
    "# storage = optuna.storages.RDBStorage(\n",
    "#     url=\"sqlite:///:memory:\",\n",
    "#     engine_kwargs={\"pool_size\": 20, \"connect_args\": {\"timeout\": 10}},\n",
    "# )\n",
    "\n",
    "# study = optuna.create_study(study_name=\"gru_model_optimization\", storage=storage)\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# # Wy≈õwietl najlepsze znalezione hiperparametry\n",
    "# best_trial = study.best_trial\n",
    "# print('Najlepsze hiperparametry:')\n",
    "# print('input_size:', best_trial.params['input_size'])\n",
    "# print('hidden_size:', best_trial.params['hidden_size'])\n",
    "# print('output_size:', best_trial.params['output_size'])\n",
    "# print('learning_rate:', best_trial.params['learning_rate'])\n",
    "# print('Najlepsza strata walidacyjna:', best_trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "deec09b4-e52a-4ac2-80b9-93f00ef114a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import optuna\n",
    "from optuna.study import Study\n",
    "from optuna.trial import Trial\n",
    "import optuna.storages\n",
    "\n",
    "# Check data types\n",
    "print(train['date'].dtype)\n",
    "print(test['date'].dtype)\n",
    "\n",
    "# Handle missing values (optional)\n",
    "if train['date'].isna().any():\n",
    "    print(\"There are missing values in 'date' column of train data\")\n",
    "    # Choose a handling method (e.g., remove rows, impute values)\n",
    "\n",
    "if test['date'].isna().any():\n",
    "    print(\"There are missing values in 'date' column of test data\")\n",
    "    # Choose a handling method for test data as well\n",
    "\n",
    "train['year'] = pd.to_datetime(train['date']).dt.year\n",
    "train['month'] = pd.to_datetime(train['date']).dt.month\n",
    "train['day'] = pd.to_datetime(train['date']).dt.day\n",
    "\n",
    "train_tensors = {\n",
    "    'year': torch.from_numpy(train['year'].to_numpy()).long(),\n",
    "    'month': torch.from_numpy(train['month'].to_numpy()).long(),\n",
    "    'day': torch.from_numpy(train['day'].to_numpy()).long(),\n",
    "    'num_sold': torch.from_numpy(train['num_sold'].to_numpy()).long(),\n",
    "    'country_Enc': torch.from_numpy(train['country_Enc'].to_numpy()).long(),\n",
    "    'store_Enc': torch.from_numpy(train['store_Enc'].to_numpy()).long(),\n",
    "    'product_Enc': torch.from_numpy(train['product_Enc'].to_numpy()).long(),\n",
    "}\n",
    "\n",
    "test['year'] = pd.to_datetime(test['date']).dt.year\n",
    "test['month'] = pd.to_datetime(test['date']).dt.month\n",
    "test['day'] = pd.to_datetime(test['date']).dt.day\n",
    "\n",
    "test_tensors = {\n",
    "    'year': torch.from_numpy(test['year'].to_numpy()).long(),\n",
    "    'month': torch.from_numpy(test['month'].to_numpy()).long(),\n",
    "    'day': torch.from_numpy(test['day'].to_numpy()).long(),\n",
    "    'country_Enc': torch.from_numpy(test['country_Enc'].to_numpy()).long(),\n",
    "    'store_Enc': torch.from_numpy(test['store_Enc'].to_numpy()).long(),\n",
    "    'product_Enc': torch.from_numpy(test['product_Enc'].to_numpy()).long(),\n",
    "}\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    train_tensors['year'],\n",
    "    train_tensors['month'],\n",
    "    train_tensors['day'],\n",
    "    train_tensors['num_sold'],\n",
    "    train_tensors['country_Enc'],\n",
    "    train_tensors['store_Enc'],\n",
    "    train_tensors['product_Enc'],\n",
    ")\n",
    "\n",
    "#### Szybka inspekcja\n",
    "train_data_np = train_dataset.tensors\n",
    "\n",
    "train_year = train_data_np[0].numpy()\n",
    "train_month = train_data_np[1].numpy()\n",
    "train_day = train_data_np[2].numpy()\n",
    "train_num_sold = train_data_np[3].numpy()\n",
    "train_country_enc = train_data_np[4].numpy()\n",
    "train_store_enc = train_data_np[5].numpy()\n",
    "train_product_enc = train_data_np[6].numpy()\n",
    "\n",
    "train_df = pd.DataFrame({\n",
    "    'year': train_year,\n",
    "    'month': train_month,\n",
    "    'day': train_day,\n",
    "    'num_sold': train_num_sold,\n",
    "    'country_Enc': train_country_enc,\n",
    "    'store_Enc': train_store_enc,\n",
    "    'product_Enc': train_product_enc\n",
    "})\n",
    "\n",
    "train_df.to_csv('prepared_train_data.csv', index=False)\n",
    "\n",
    "####\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(\n",
    "    train_tensors['year'],\n",
    "    train_tensors['month'],\n",
    "    train_tensors['day'],\n",
    "    train_tensors['country_Enc'],\n",
    "    train_tensors['store_Enc'],\n",
    "    train_tensors['product_Enc'],\n",
    ")\n",
    "\n",
    "  # Zdefiniuj ≈Çadowarki danych\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48ebd7e0-eb1a-4183-88e8-ee97cd5973d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-08 20:24:27,643] A new study created in memory with name: no-name-aa37de2f-452d-4ef4-9b02-8d8485005620\n",
      "[W 2024-05-08 20:24:27,651] Trial 0 failed with parameters: {'input_dim': 43, 'hidden_size': 200, 'output_size': 8, 'learning_rate': 0.009513325991333322} because of the following error: ValueError('too many values to unpack (expected 3)').\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\domin\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\domin\\AppData\\Local\\Temp\\ipykernel_61800\\1477774750.py\", line 53, in objective\n",
      "    train(model, optimizer, train_loader, criterion)\n",
      "  File \"C:\\Users\\domin\\AppData\\Local\\Temp\\ipykernel_61800\\1477774750.py\", line 32, in train\n",
      "    for data, target, extra_element in train_loader:  # Assuming an extra element\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: too many values to unpack (expected 3)\n",
      "[W 2024-05-08 20:24:27,652] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Create Optuna study and optimize\u001b[39;00m\n\u001b[0;32m     71\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[0;32m     63\u001b[0m             study,\n\u001b[0;32m     64\u001b[0m             func,\n\u001b[0;32m     65\u001b[0m             n_trials,\n\u001b[0;32m     66\u001b[0m             timeout,\n\u001b[0;32m     67\u001b[0m             catch,\n\u001b[0;32m     68\u001b[0m             callbacks,\n\u001b[0;32m     69\u001b[0m             gc_after_trial,\n\u001b[0;32m     70\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[62], line 53\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     51\u001b[0m epochs_no_improvement \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m25\u001b[39m):\n\u001b[1;32m---> 53\u001b[0m     train(model, optimizer, train_loader, criterion)\n\u001b[0;32m     54\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m validate(model, test_loader, criterion)\n\u001b[0;32m     55\u001b[0m     trial\u001b[38;5;241m.\u001b[39mreport(val_loss, step\u001b[38;5;241m=\u001b[39mepoch)\n",
      "Cell \u001b[1;32mIn[62], line 32\u001b[0m, in \u001b[0;36mobjective.<locals>.train\u001b[1;34m(model, optimizer, train_loader, criterion)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, optimizer, train_loader, criterion):\n\u001b[0;32m     31\u001b[0m    model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 32\u001b[0m    \u001b[38;5;28;01mfor\u001b[39;00m data, target, extra_element \u001b[38;5;129;01min\u001b[39;00m train_loader:  \u001b[38;5;66;03m# Assuming an extra element\u001b[39;00m\n\u001b[0;32m     33\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     34\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(data)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define GRU model\n",
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers=1)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.gru(x)\n",
    "        x = x[-1]  # Get the last hidden state\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters with Optuna\n",
    "    input_dim = trial.suggest_int('input_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_size', 32, 256)  # Use hidden_size for consistency\n",
    "    output_dim = trial.suggest_int('output_size', 1, 10)  # Use output_size for consistency\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2)\n",
    "\n",
    "    model = GRUNet(input_dim, hidden_dim, output_dim)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    # Implement training and validation functions\n",
    "    def train(model, optimizer, train_loader, criterion):\n",
    "       model.train()\n",
    "       for data, target, extra_element in train_loader:  # Assuming an extra element\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def validate(model, test_loader, criterion):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            for data, target in test_loader:\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                losses.append(loss.item())\n",
    "            return sum(losses) / len(losses)\n",
    "\n",
    "    # Training and Validation with Early Stopping (Optional)\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improvement = 0\n",
    "    for epoch in range(25):\n",
    "        train(model, optimizer, train_loader, criterion)\n",
    "        val_loss = validate(model, test_loader, criterion)\n",
    "        trial.report(val_loss, step=epoch)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improvement = 0\n",
    "        else:\n",
    "            epochs_no_improvement += 1\n",
    "\n",
    "        if epochs_no_improvement >= 5:  # Adjust this threshold as needed\n",
    "            print(\"Early stopping at epoch\", epoch)\n",
    "            break\n",
    "\n",
    "    return best_val_loss\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455ba13-b5e3-4331-bfd9-4dc8b8aff868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
